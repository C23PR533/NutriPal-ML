{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "from typing import Dict, Text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_user_data = pd.read_json('../results/user_dataset.json')\n",
    "raw_food_data = pd.read_json('../results/output.json')\n",
    "listUserPreferences = pd.DataFrame(\n",
    "    [data for data in raw_user_data.listUserPreferences])\n",
    "listFoodPreferences = pd.DataFrame(\n",
    "    [data for data in raw_food_data.food])\n",
    "temp = pd.DataFrame(\n",
    "    [data for data in listFoodPreferences.servings])\n",
    "listFoodServings = pd.DataFrame(\n",
    "    [item for sublist in temp.serving for item in sublist])\n",
    "listFoodPreferences = listFoodPreferences.drop(columns=['servings'])\n",
    "raw_listFood = listFoodPreferences.merge(\n",
    "    listFoodServings, how='left', left_index=True, right_index=True)\n",
    "listFood = raw_listFood.fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>weight</th>\n",
       "      <th>id_user</th>\n",
       "      <th>activityLevel</th>\n",
       "      <th>goals</th>\n",
       "      <th>height</th>\n",
       "      <th>disease</th>\n",
       "      <th>favoriteFood</th>\n",
       "      <th>birthdate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>50</td>\n",
       "      <td>3222915</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Chicken Cordon Bleu, Chocolate Mousse Cake, S...</td>\n",
       "      <td>20-10-1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>46</td>\n",
       "      <td>9930952</td>\n",
       "      <td>1.725</td>\n",
       "      <td>0</td>\n",
       "      <td>151</td>\n",
       "      <td>[obesity]</td>\n",
       "      <td>[Samosa, Pizza Dough, Baguette, Chocolate Mous...</td>\n",
       "      <td>10-09-1976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>60</td>\n",
       "      <td>3717984</td>\n",
       "      <td>1.725</td>\n",
       "      <td>0</td>\n",
       "      <td>164</td>\n",
       "      <td>[heart, hypertension]</td>\n",
       "      <td>[Bubur Ayam, Mashed Potato, Puff Pastry, Chick...</td>\n",
       "      <td>01-05-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>41</td>\n",
       "      <td>6726690</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0</td>\n",
       "      <td>156</td>\n",
       "      <td>[diabetes, heart, obesity]</td>\n",
       "      <td>[Fish Cake, Red Velvet, Black Forest, Guacamol...</td>\n",
       "      <td>02-06-1979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Female</td>\n",
       "      <td>66</td>\n",
       "      <td>6452326</td>\n",
       "      <td>1.2</td>\n",
       "      <td>-500</td>\n",
       "      <td>151</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Puff Pastry, Mashed Potato, Bubur Ayam, Okono...</td>\n",
       "      <td>22-03-1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>Male</td>\n",
       "      <td>65</td>\n",
       "      <td>7559844</td>\n",
       "      <td>1.55</td>\n",
       "      <td>500</td>\n",
       "      <td>163</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Chicken Cordon Bleu, Pad Thai, Churros, Black...</td>\n",
       "      <td>26-01-1975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>Male</td>\n",
       "      <td>84</td>\n",
       "      <td>8260717</td>\n",
       "      <td>1.9</td>\n",
       "      <td>500</td>\n",
       "      <td>196</td>\n",
       "      <td>[heart]</td>\n",
       "      <td>[Bibimbap, Puff Pastry, Thai Tea, Churros, Cin...</td>\n",
       "      <td>14-05-1950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>Female</td>\n",
       "      <td>47</td>\n",
       "      <td>4895731</td>\n",
       "      <td>1.55</td>\n",
       "      <td>-500</td>\n",
       "      <td>180</td>\n",
       "      <td>[diabetes, heart]</td>\n",
       "      <td>[Chocolate Lava Cake, Meringue Cookies, Takoya...</td>\n",
       "      <td>21-07-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>Male</td>\n",
       "      <td>63</td>\n",
       "      <td>7540747</td>\n",
       "      <td>1.55</td>\n",
       "      <td>500</td>\n",
       "      <td>183</td>\n",
       "      <td>[diabetes, hypertension, obesity]</td>\n",
       "      <td>[Thai Tea, Chocolate Mousse Cake, Pad Thai, Me...</td>\n",
       "      <td>22-10-1952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>Male</td>\n",
       "      <td>59</td>\n",
       "      <td>7385894</td>\n",
       "      <td>1.9</td>\n",
       "      <td>500</td>\n",
       "      <td>169</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Churros, Kebab, Salmon Teriyaki, Burger Bun, ...</td>\n",
       "      <td>14-05-2006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>265 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     gender weight  id_user activityLevel goals height  \\\n",
       "0      Male     50  3222915           1.9     0    180   \n",
       "1      Male     46  9930952         1.725     0    151   \n",
       "2      Male     60  3717984         1.725     0    164   \n",
       "3      Male     41  6726690          1.55     0    156   \n",
       "4    Female     66  6452326           1.2  -500    151   \n",
       "..      ...    ...      ...           ...   ...    ...   \n",
       "260    Male     65  7559844          1.55   500    163   \n",
       "261    Male     84  8260717           1.9   500    196   \n",
       "262  Female     47  4895731          1.55  -500    180   \n",
       "263    Male     63  7540747          1.55   500    183   \n",
       "264    Male     59  7385894           1.9   500    169   \n",
       "\n",
       "                               disease  \\\n",
       "0                                   []   \n",
       "1                            [obesity]   \n",
       "2                [heart, hypertension]   \n",
       "3           [diabetes, heart, obesity]   \n",
       "4                                   []   \n",
       "..                                 ...   \n",
       "260                                 []   \n",
       "261                            [heart]   \n",
       "262                  [diabetes, heart]   \n",
       "263  [diabetes, hypertension, obesity]   \n",
       "264                                 []   \n",
       "\n",
       "                                          favoriteFood   birthdate  \n",
       "0    [Chicken Cordon Bleu, Chocolate Mousse Cake, S...  20-10-1990  \n",
       "1    [Samosa, Pizza Dough, Baguette, Chocolate Mous...  10-09-1976  \n",
       "2    [Bubur Ayam, Mashed Potato, Puff Pastry, Chick...  01-05-2019  \n",
       "3    [Fish Cake, Red Velvet, Black Forest, Guacamol...  02-06-1979  \n",
       "4    [Puff Pastry, Mashed Potato, Bubur Ayam, Okono...  22-03-1988  \n",
       "..                                                 ...         ...  \n",
       "260  [Chicken Cordon Bleu, Pad Thai, Churros, Black...  26-01-1975  \n",
       "261  [Bibimbap, Puff Pastry, Thai Tea, Churros, Cin...  14-05-1950  \n",
       "262  [Chocolate Lava Cake, Meringue Cookies, Takoya...  21-07-2016  \n",
       "263  [Thai Tea, Chocolate Mousse Cake, Pad Thai, Me...  22-10-1952  \n",
       "264  [Churros, Kebab, Salmon Teriyaki, Burger Bun, ...  14-05-2006  \n",
       "\n",
       "[265 rows x 9 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listUserPreferences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>food_id</th>\n",
       "      <th>food_name</th>\n",
       "      <th>food_type</th>\n",
       "      <th>food_url</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>calcium</th>\n",
       "      <th>calories</th>\n",
       "      <th>carbohydrate</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>fat</th>\n",
       "      <th>...</th>\n",
       "      <th>serving_description</th>\n",
       "      <th>serving_id</th>\n",
       "      <th>serving_url</th>\n",
       "      <th>sodium</th>\n",
       "      <th>sugar</th>\n",
       "      <th>trans_fat</th>\n",
       "      <th>vitamin_a</th>\n",
       "      <th>vitamin_c</th>\n",
       "      <th>added_sugars</th>\n",
       "      <th>vitamin_d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2655309</td>\n",
       "      <td>Kebab</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://www.fatsecret.com/calories-nutrition/g...</td>\n",
       "      <td>0</td>\n",
       "      <td>176</td>\n",
       "      <td>620</td>\n",
       "      <td>77.10</td>\n",
       "      <td>53</td>\n",
       "      <td>16.63</td>\n",
       "      <td>...</td>\n",
       "      <td>1 kebab</td>\n",
       "      <td>2590791</td>\n",
       "      <td>https://www.fatsecret.com/calories-nutrition/g...</td>\n",
       "      <td>1029</td>\n",
       "      <td>6.91</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>22.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58704864</td>\n",
       "      <td>Gyoza</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://www.fatsecret.com/calories-nutrition/h...</td>\n",
       "      <td>Hungry Planet</td>\n",
       "      <td>176</td>\n",
       "      <td>620</td>\n",
       "      <td>77.10</td>\n",
       "      <td>53</td>\n",
       "      <td>16.63</td>\n",
       "      <td>...</td>\n",
       "      <td>1 serving (390 g)</td>\n",
       "      <td>2590792</td>\n",
       "      <td>https://www.fatsecret.com/calories-nutrition/g...</td>\n",
       "      <td>1029</td>\n",
       "      <td>6.91</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>22.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68848666</td>\n",
       "      <td>Gyoza</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://www.fatsecret.com/calories-nutrition/y...</td>\n",
       "      <td>Yoshinoya</td>\n",
       "      <td>45</td>\n",
       "      <td>159</td>\n",
       "      <td>19.77</td>\n",
       "      <td>13</td>\n",
       "      <td>4.27</td>\n",
       "      <td>...</td>\n",
       "      <td>100 g</td>\n",
       "      <td>2590793</td>\n",
       "      <td>https://www.fatsecret.com/calories-nutrition/g...</td>\n",
       "      <td>264</td>\n",
       "      <td>1.77</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>5.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>515347</td>\n",
       "      <td>Gyoza</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://www.fatsecret.com/calories-nutrition/t...</td>\n",
       "      <td>Tokyo Joe's</td>\n",
       "      <td>13</td>\n",
       "      <td>45</td>\n",
       "      <td>5.60</td>\n",
       "      <td>4</td>\n",
       "      <td>1.21</td>\n",
       "      <td>...</td>\n",
       "      <td>1 oz</td>\n",
       "      <td>2590794</td>\n",
       "      <td>https://www.fatsecret.com/calories-nutrition/g...</td>\n",
       "      <td>75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1684073</td>\n",
       "      <td>Chicken Katsu</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://www.fatsecret.com/calories-nutrition/l...</td>\n",
       "      <td>L&amp;L Hawaiian Barbecue</td>\n",
       "      <td>30</td>\n",
       "      <td>120</td>\n",
       "      <td>17.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>...</td>\n",
       "      <td>4 gyoza</td>\n",
       "      <td>48898797</td>\n",
       "      <td>https://www.fatsecret.com/calories-nutrition/h...</td>\n",
       "      <td>280</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>447317</td>\n",
       "      <td>Guacamole</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://www.fatsecret.com/calories-nutrition/c...</td>\n",
       "      <td>Chevy's Fresh Mex</td>\n",
       "      <td>0</td>\n",
       "      <td>330</td>\n",
       "      <td>41.00</td>\n",
       "      <td>0</td>\n",
       "      <td>15.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1 serving</td>\n",
       "      <td>56535626</td>\n",
       "      <td>https://www.fatsecret.com/calories-nutrition/r...</td>\n",
       "      <td>390</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>2125933</td>\n",
       "      <td>Guacamole</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://www.fatsecret.com/calories-nutrition/c...</td>\n",
       "      <td>Costa Vida</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>12.00</td>\n",
       "      <td>0</td>\n",
       "      <td>4.50</td>\n",
       "      <td>...</td>\n",
       "      <td>1 croissant</td>\n",
       "      <td>44521664</td>\n",
       "      <td>https://www.fatsecret.com/calories-nutrition/p...</td>\n",
       "      <td>210</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>1995633</td>\n",
       "      <td>Guacamole</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://www.fatsecret.com/calories-nutrition/o...</td>\n",
       "      <td>Ortega</td>\n",
       "      <td>0</td>\n",
       "      <td>264</td>\n",
       "      <td>28.90</td>\n",
       "      <td>0</td>\n",
       "      <td>13.80</td>\n",
       "      <td>...</td>\n",
       "      <td>1 serving</td>\n",
       "      <td>56209720</td>\n",
       "      <td>https://www.fatsecret.com/calories-nutrition/t...</td>\n",
       "      <td>246</td>\n",
       "      <td>3.90</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>99383</td>\n",
       "      <td>Guacamole</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://www.fatsecret.com/calories-nutrition/c...</td>\n",
       "      <td>Chili's</td>\n",
       "      <td>0</td>\n",
       "      <td>250</td>\n",
       "      <td>25.00</td>\n",
       "      <td>35</td>\n",
       "      <td>14.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1 serving</td>\n",
       "      <td>4438697</td>\n",
       "      <td>https://www.fatsecret.com/calories-nutrition/s...</td>\n",
       "      <td>230</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>69852</td>\n",
       "      <td>Guacamole</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://www.fatsecret.com/calories-nutrition/f...</td>\n",
       "      <td>Freebirds</td>\n",
       "      <td>0</td>\n",
       "      <td>340</td>\n",
       "      <td>39.00</td>\n",
       "      <td>60</td>\n",
       "      <td>16.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1 croissant</td>\n",
       "      <td>864426</td>\n",
       "      <td>https://www.fatsecret.com/calories-nutrition/c...</td>\n",
       "      <td>370</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>265 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      food_id      food_name food_type  \\\n",
       "0     2655309          Kebab        []   \n",
       "1    58704864          Gyoza        []   \n",
       "2    68848666          Gyoza        []   \n",
       "3      515347          Gyoza        []   \n",
       "4     1684073  Chicken Katsu        []   \n",
       "..        ...            ...       ...   \n",
       "260    447317      Guacamole        []   \n",
       "261   2125933      Guacamole        []   \n",
       "262   1995633      Guacamole        []   \n",
       "263     99383      Guacamole        []   \n",
       "264     69852      Guacamole        []   \n",
       "\n",
       "                                              food_url             brand_name  \\\n",
       "0    https://www.fatsecret.com/calories-nutrition/g...                      0   \n",
       "1    https://www.fatsecret.com/calories-nutrition/h...          Hungry Planet   \n",
       "2    https://www.fatsecret.com/calories-nutrition/y...              Yoshinoya   \n",
       "3    https://www.fatsecret.com/calories-nutrition/t...            Tokyo Joe's   \n",
       "4    https://www.fatsecret.com/calories-nutrition/l...  L&L Hawaiian Barbecue   \n",
       "..                                                 ...                    ...   \n",
       "260  https://www.fatsecret.com/calories-nutrition/c...      Chevy's Fresh Mex   \n",
       "261  https://www.fatsecret.com/calories-nutrition/c...             Costa Vida   \n",
       "262  https://www.fatsecret.com/calories-nutrition/o...                 Ortega   \n",
       "263  https://www.fatsecret.com/calories-nutrition/c...                Chili's   \n",
       "264  https://www.fatsecret.com/calories-nutrition/f...              Freebirds   \n",
       "\n",
       "    calcium calories carbohydrate cholesterol    fat  ... serving_description  \\\n",
       "0       176      620        77.10          53  16.63  ...             1 kebab   \n",
       "1       176      620        77.10          53  16.63  ...   1 serving (390 g)   \n",
       "2        45      159        19.77          13   4.27  ...               100 g   \n",
       "3        13       45         5.60           4   1.21  ...                1 oz   \n",
       "4        30      120        17.00           0   2.50  ...             4 gyoza   \n",
       "..      ...      ...          ...         ...    ...  ...                 ...   \n",
       "260       0      330        41.00           0  15.00  ...           1 serving   \n",
       "261       0      100        12.00           0   4.50  ...         1 croissant   \n",
       "262       0      264        28.90           0  13.80  ...           1 serving   \n",
       "263       0      250        25.00          35  14.00  ...           1 serving   \n",
       "264       0      340        39.00          60  16.00  ...         1 croissant   \n",
       "\n",
       "    serving_id                                        serving_url sodium  \\\n",
       "0      2590791  https://www.fatsecret.com/calories-nutrition/g...   1029   \n",
       "1      2590792  https://www.fatsecret.com/calories-nutrition/g...   1029   \n",
       "2      2590793  https://www.fatsecret.com/calories-nutrition/g...    264   \n",
       "3      2590794  https://www.fatsecret.com/calories-nutrition/g...     75   \n",
       "4     48898797  https://www.fatsecret.com/calories-nutrition/h...    280   \n",
       "..         ...                                                ...    ...   \n",
       "260   56535626  https://www.fatsecret.com/calories-nutrition/r...    390   \n",
       "261   44521664  https://www.fatsecret.com/calories-nutrition/p...    210   \n",
       "262   56209720  https://www.fatsecret.com/calories-nutrition/t...    246   \n",
       "263    4438697  https://www.fatsecret.com/calories-nutrition/s...    230   \n",
       "264     864426  https://www.fatsecret.com/calories-nutrition/c...    370   \n",
       "\n",
       "    sugar trans_fat vitamin_a vitamin_c added_sugars vitamin_d  \n",
       "0    6.91         0        37      22.2            0         0  \n",
       "1    6.91         0        37      22.2            0         0  \n",
       "2    1.77         0         9       5.7            0         0  \n",
       "3    0.50         0         3       1.6            0         0  \n",
       "4    1.00         0         0         0         1.00         0  \n",
       "..    ...       ...       ...       ...          ...       ...  \n",
       "260  6.00     0.500         0         0            0         0  \n",
       "261  3.00         0         0         0            0         0  \n",
       "262  3.90     0.100         0         0            0         0  \n",
       "263  3.00         0         0         0            0         0  \n",
       "264  6.00         0         0         0            0         0  \n",
       "\n",
       "[265 rows x 31 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listFood\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              Kebab\n",
       "1              Gyoza\n",
       "2              Gyoza\n",
       "3              Gyoza\n",
       "4      Chicken Katsu\n",
       "           ...      \n",
       "260        Guacamole\n",
       "261        Guacamole\n",
       "262        Guacamole\n",
       "263        Guacamole\n",
       "264        Guacamole\n",
       "Name: food_name, Length: 265, dtype: object"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the list columns to strings\n",
    "listFood['food_name'] = listFood['food_name'].astype(str)\n",
    "# listUserPreferences['favoriteFood'] = listUserPreferences['favoriteFood'].astype(str).apply(eval).apply(lambda x: ', '.join(x))\n",
    "listUserPreferences = listUserPreferences.explode('favoriteFood')\n",
    "listFood['food_name']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Chicken Cordon Bleu\n",
       "0      Chocolate Mousse Cake\n",
       "0                     Samosa\n",
       "0               Cream Cheese\n",
       "0                Carrot Cake\n",
       "               ...          \n",
       "264          Salmon Teriyaki\n",
       "264               Burger Bun\n",
       "264                 Pad Thai\n",
       "264              Onion Rings\n",
       "264                 Takoyaki\n",
       "Name: favoriteFood, Length: 1981, dtype: object"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "listUserPreferences['favoriteFood']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 11193 entries, 0 to 11192\n",
      "Data columns (total 40 columns):\n",
      " #   Column                   Non-Null Count  Dtype \n",
      "---  ------                   --------------  ----- \n",
      " 0   food_id                  11193 non-null  object\n",
      " 1   food_name                11193 non-null  object\n",
      " 2   food_type                11193 non-null  object\n",
      " 3   food_url                 11193 non-null  object\n",
      " 4   brand_name               11193 non-null  object\n",
      " 5   calcium                  11193 non-null  object\n",
      " 6   calories                 11193 non-null  object\n",
      " 7   carbohydrate             11193 non-null  object\n",
      " 8   cholesterol              11193 non-null  object\n",
      " 9   fat                      11193 non-null  object\n",
      " 10  fiber                    11193 non-null  object\n",
      " 11  iron                     11193 non-null  object\n",
      " 12  measurement_description  11193 non-null  object\n",
      " 13  metric_serving_amount    11193 non-null  object\n",
      " 14  metric_serving_unit      11193 non-null  object\n",
      " 15  monounsaturated_fat      11193 non-null  object\n",
      " 16  number_of_units          11193 non-null  object\n",
      " 17  polyunsaturated_fat      11193 non-null  object\n",
      " 18  potassium                11193 non-null  object\n",
      " 19  protein                  11193 non-null  object\n",
      " 20  saturated_fat            11193 non-null  object\n",
      " 21  serving_description      11193 non-null  object\n",
      " 22  serving_id               11193 non-null  object\n",
      " 23  serving_url              11193 non-null  object\n",
      " 24  sodium                   11193 non-null  object\n",
      " 25  sugar                    11193 non-null  object\n",
      " 26  trans_fat                11193 non-null  object\n",
      " 27  vitamin_a                11193 non-null  object\n",
      " 28  vitamin_c                11193 non-null  object\n",
      " 29  added_sugars             11193 non-null  object\n",
      " 30  vitamin_d                11193 non-null  object\n",
      " 31  gender                   11193 non-null  object\n",
      " 32  weight                   11193 non-null  object\n",
      " 33  id_user                  11193 non-null  object\n",
      " 34  activityLevel            11193 non-null  object\n",
      " 35  goals                    11193 non-null  object\n",
      " 36  height                   11193 non-null  object\n",
      " 37  disease                  11193 non-null  object\n",
      " 38  favoriteFood             11193 non-null  object\n",
      " 39  birthdate                11193 non-null  object\n",
      "dtypes: object(40)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# Merge the DataFrames based on the common attribute, such as food name or ID\n",
    "raw_merged_df = pd.merge(listFood, listUserPreferences,\n",
    "                         left_on='food_name', right_on='favoriteFood', how='inner')\n",
    "\n",
    "raw_merged_df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>food_id</th>\n",
       "      <th>food_name</th>\n",
       "      <th>food_type</th>\n",
       "      <th>food_url</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>calcium</th>\n",
       "      <th>calories</th>\n",
       "      <th>carbohydrate</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>fat</th>\n",
       "      <th>...</th>\n",
       "      <th>vitamin_d</th>\n",
       "      <th>gender</th>\n",
       "      <th>weight</th>\n",
       "      <th>id_user</th>\n",
       "      <th>activityLevel</th>\n",
       "      <th>goals</th>\n",
       "      <th>height</th>\n",
       "      <th>disease</th>\n",
       "      <th>favoriteFood</th>\n",
       "      <th>birthdate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2655309</td>\n",
       "      <td>Kebab</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://www.fatsecret.com/calories-nutrition/g...</td>\n",
       "      <td>0</td>\n",
       "      <td>176</td>\n",
       "      <td>620</td>\n",
       "      <td>77.10</td>\n",
       "      <td>53</td>\n",
       "      <td>16.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Male</td>\n",
       "      <td>43</td>\n",
       "      <td>3847302</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0</td>\n",
       "      <td>196</td>\n",
       "      <td>[obesity, diabetes, heart, hypertension]</td>\n",
       "      <td>Kebab</td>\n",
       "      <td>09-01-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2655309</td>\n",
       "      <td>Kebab</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://www.fatsecret.com/calories-nutrition/g...</td>\n",
       "      <td>0</td>\n",
       "      <td>176</td>\n",
       "      <td>620</td>\n",
       "      <td>77.10</td>\n",
       "      <td>53</td>\n",
       "      <td>16.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Male</td>\n",
       "      <td>54</td>\n",
       "      <td>2935940</td>\n",
       "      <td>1.55</td>\n",
       "      <td>500</td>\n",
       "      <td>189</td>\n",
       "      <td>[heart, diabetes, obesity, hypertension]</td>\n",
       "      <td>Kebab</td>\n",
       "      <td>26-08-1967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2655309</td>\n",
       "      <td>Kebab</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://www.fatsecret.com/calories-nutrition/g...</td>\n",
       "      <td>0</td>\n",
       "      <td>176</td>\n",
       "      <td>620</td>\n",
       "      <td>77.10</td>\n",
       "      <td>53</td>\n",
       "      <td>16.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>5259626</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>199</td>\n",
       "      <td>[heart, hypertension, obesity, diabetes]</td>\n",
       "      <td>Kebab</td>\n",
       "      <td>20-01-1972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2655309</td>\n",
       "      <td>Kebab</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://www.fatsecret.com/calories-nutrition/g...</td>\n",
       "      <td>0</td>\n",
       "      <td>176</td>\n",
       "      <td>620</td>\n",
       "      <td>77.10</td>\n",
       "      <td>53</td>\n",
       "      <td>16.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Male</td>\n",
       "      <td>82</td>\n",
       "      <td>2097001</td>\n",
       "      <td>1.2</td>\n",
       "      <td>500</td>\n",
       "      <td>181</td>\n",
       "      <td>[hypertension, diabetes, heart, obesity]</td>\n",
       "      <td>Kebab</td>\n",
       "      <td>20-03-1978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2655309</td>\n",
       "      <td>Kebab</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://www.fatsecret.com/calories-nutrition/g...</td>\n",
       "      <td>0</td>\n",
       "      <td>176</td>\n",
       "      <td>620</td>\n",
       "      <td>77.10</td>\n",
       "      <td>53</td>\n",
       "      <td>16.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Male</td>\n",
       "      <td>84</td>\n",
       "      <td>7545290</td>\n",
       "      <td>1.375</td>\n",
       "      <td>-500</td>\n",
       "      <td>153</td>\n",
       "      <td>[diabetes]</td>\n",
       "      <td>Kebab</td>\n",
       "      <td>21-04-2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11188</th>\n",
       "      <td>69852</td>\n",
       "      <td>Guacamole</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://www.fatsecret.com/calories-nutrition/f...</td>\n",
       "      <td>Freebirds</td>\n",
       "      <td>0</td>\n",
       "      <td>340</td>\n",
       "      <td>39.00</td>\n",
       "      <td>60</td>\n",
       "      <td>16.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Female</td>\n",
       "      <td>92</td>\n",
       "      <td>8630293</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>159</td>\n",
       "      <td>[hypertension]</td>\n",
       "      <td>Guacamole</td>\n",
       "      <td>28-12-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11189</th>\n",
       "      <td>69852</td>\n",
       "      <td>Guacamole</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://www.fatsecret.com/calories-nutrition/f...</td>\n",
       "      <td>Freebirds</td>\n",
       "      <td>0</td>\n",
       "      <td>340</td>\n",
       "      <td>39.00</td>\n",
       "      <td>60</td>\n",
       "      <td>16.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Male</td>\n",
       "      <td>70</td>\n",
       "      <td>3959643</td>\n",
       "      <td>1.375</td>\n",
       "      <td>500</td>\n",
       "      <td>163</td>\n",
       "      <td>[diabetes, obesity, heart]</td>\n",
       "      <td>Guacamole</td>\n",
       "      <td>27-02-2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11190</th>\n",
       "      <td>69852</td>\n",
       "      <td>Guacamole</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://www.fatsecret.com/calories-nutrition/f...</td>\n",
       "      <td>Freebirds</td>\n",
       "      <td>0</td>\n",
       "      <td>340</td>\n",
       "      <td>39.00</td>\n",
       "      <td>60</td>\n",
       "      <td>16.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Female</td>\n",
       "      <td>70</td>\n",
       "      <td>9023340</td>\n",
       "      <td>1.2</td>\n",
       "      <td>-500</td>\n",
       "      <td>191</td>\n",
       "      <td>[hypertension, diabetes, heart, obesity]</td>\n",
       "      <td>Guacamole</td>\n",
       "      <td>24-11-1965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11191</th>\n",
       "      <td>69852</td>\n",
       "      <td>Guacamole</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://www.fatsecret.com/calories-nutrition/f...</td>\n",
       "      <td>Freebirds</td>\n",
       "      <td>0</td>\n",
       "      <td>340</td>\n",
       "      <td>39.00</td>\n",
       "      <td>60</td>\n",
       "      <td>16.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Female</td>\n",
       "      <td>98</td>\n",
       "      <td>1433326</td>\n",
       "      <td>1.55</td>\n",
       "      <td>500</td>\n",
       "      <td>164</td>\n",
       "      <td>[obesity]</td>\n",
       "      <td>Guacamole</td>\n",
       "      <td>25-06-1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11192</th>\n",
       "      <td>69852</td>\n",
       "      <td>Guacamole</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://www.fatsecret.com/calories-nutrition/f...</td>\n",
       "      <td>Freebirds</td>\n",
       "      <td>0</td>\n",
       "      <td>340</td>\n",
       "      <td>39.00</td>\n",
       "      <td>60</td>\n",
       "      <td>16.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>3356380</td>\n",
       "      <td>1.55</td>\n",
       "      <td>-500</td>\n",
       "      <td>163</td>\n",
       "      <td>[heart]</td>\n",
       "      <td>Guacamole</td>\n",
       "      <td>17-03-1965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11193 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       food_id  food_name food_type  \\\n",
       "0      2655309      Kebab        []   \n",
       "1      2655309      Kebab        []   \n",
       "2      2655309      Kebab        []   \n",
       "3      2655309      Kebab        []   \n",
       "4      2655309      Kebab        []   \n",
       "...        ...        ...       ...   \n",
       "11188    69852  Guacamole        []   \n",
       "11189    69852  Guacamole        []   \n",
       "11190    69852  Guacamole        []   \n",
       "11191    69852  Guacamole        []   \n",
       "11192    69852  Guacamole        []   \n",
       "\n",
       "                                                food_url brand_name calcium  \\\n",
       "0      https://www.fatsecret.com/calories-nutrition/g...          0     176   \n",
       "1      https://www.fatsecret.com/calories-nutrition/g...          0     176   \n",
       "2      https://www.fatsecret.com/calories-nutrition/g...          0     176   \n",
       "3      https://www.fatsecret.com/calories-nutrition/g...          0     176   \n",
       "4      https://www.fatsecret.com/calories-nutrition/g...          0     176   \n",
       "...                                                  ...        ...     ...   \n",
       "11188  https://www.fatsecret.com/calories-nutrition/f...  Freebirds       0   \n",
       "11189  https://www.fatsecret.com/calories-nutrition/f...  Freebirds       0   \n",
       "11190  https://www.fatsecret.com/calories-nutrition/f...  Freebirds       0   \n",
       "11191  https://www.fatsecret.com/calories-nutrition/f...  Freebirds       0   \n",
       "11192  https://www.fatsecret.com/calories-nutrition/f...  Freebirds       0   \n",
       "\n",
       "      calories carbohydrate cholesterol    fat  ... vitamin_d  gender weight  \\\n",
       "0          620        77.10          53  16.63  ...         0    Male     43   \n",
       "1          620        77.10          53  16.63  ...         0    Male     54   \n",
       "2          620        77.10          53  16.63  ...         0    Male     40   \n",
       "3          620        77.10          53  16.63  ...         0    Male     82   \n",
       "4          620        77.10          53  16.63  ...         0    Male     84   \n",
       "...        ...          ...         ...    ...  ...       ...     ...    ...   \n",
       "11188      340        39.00          60  16.00  ...         0  Female     92   \n",
       "11189      340        39.00          60  16.00  ...         0    Male     70   \n",
       "11190      340        39.00          60  16.00  ...         0  Female     70   \n",
       "11191      340        39.00          60  16.00  ...         0  Female     98   \n",
       "11192      340        39.00          60  16.00  ...         0  Female     42   \n",
       "\n",
       "       id_user activityLevel goals height  \\\n",
       "0      3847302          1.55     0    196   \n",
       "1      2935940          1.55   500    189   \n",
       "2      5259626           1.2     0    199   \n",
       "3      2097001           1.2   500    181   \n",
       "4      7545290         1.375  -500    153   \n",
       "...        ...           ...   ...    ...   \n",
       "11188  8630293           1.2     0    159   \n",
       "11189  3959643         1.375   500    163   \n",
       "11190  9023340           1.2  -500    191   \n",
       "11191  1433326          1.55   500    164   \n",
       "11192  3356380          1.55  -500    163   \n",
       "\n",
       "                                        disease favoriteFood   birthdate  \n",
       "0      [obesity, diabetes, heart, hypertension]        Kebab  09-01-2019  \n",
       "1      [heart, diabetes, obesity, hypertension]        Kebab  26-08-1967  \n",
       "2      [heart, hypertension, obesity, diabetes]        Kebab  20-01-1972  \n",
       "3      [hypertension, diabetes, heart, obesity]        Kebab  20-03-1978  \n",
       "4                                    [diabetes]        Kebab  21-04-2014  \n",
       "...                                         ...          ...         ...  \n",
       "11188                            [hypertension]    Guacamole  28-12-2020  \n",
       "11189                [diabetes, obesity, heart]    Guacamole  27-02-2005  \n",
       "11190  [hypertension, diabetes, heart, obesity]    Guacamole  24-11-1965  \n",
       "11191                                 [obesity]    Guacamole  25-06-1991  \n",
       "11192                                   [heart]    Guacamole  17-03-1965  \n",
       "\n",
       "[11193 rows x 40 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>food_id</th>\n",
       "      <th>food_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>id_user</th>\n",
       "      <th>gender</th>\n",
       "      <th>disease</th>\n",
       "      <th>favoriteFood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2655309</td>\n",
       "      <td>Kebab</td>\n",
       "      <td>0</td>\n",
       "      <td>3847302</td>\n",
       "      <td>Male</td>\n",
       "      <td>obesity, diabetes, heart, hypertension</td>\n",
       "      <td>Kebab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2655309</td>\n",
       "      <td>Kebab</td>\n",
       "      <td>0</td>\n",
       "      <td>2935940</td>\n",
       "      <td>Male</td>\n",
       "      <td>heart, diabetes, obesity, hypertension</td>\n",
       "      <td>Kebab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2655309</td>\n",
       "      <td>Kebab</td>\n",
       "      <td>0</td>\n",
       "      <td>5259626</td>\n",
       "      <td>Male</td>\n",
       "      <td>heart, hypertension, obesity, diabetes</td>\n",
       "      <td>Kebab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2655309</td>\n",
       "      <td>Kebab</td>\n",
       "      <td>0</td>\n",
       "      <td>2097001</td>\n",
       "      <td>Male</td>\n",
       "      <td>hypertension, diabetes, heart, obesity</td>\n",
       "      <td>Kebab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2655309</td>\n",
       "      <td>Kebab</td>\n",
       "      <td>0</td>\n",
       "      <td>7545290</td>\n",
       "      <td>Male</td>\n",
       "      <td>diabetes</td>\n",
       "      <td>Kebab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11188</th>\n",
       "      <td>69852</td>\n",
       "      <td>Guacamole</td>\n",
       "      <td>Freebirds</td>\n",
       "      <td>8630293</td>\n",
       "      <td>Female</td>\n",
       "      <td>hypertension</td>\n",
       "      <td>Guacamole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11189</th>\n",
       "      <td>69852</td>\n",
       "      <td>Guacamole</td>\n",
       "      <td>Freebirds</td>\n",
       "      <td>3959643</td>\n",
       "      <td>Male</td>\n",
       "      <td>diabetes, obesity, heart</td>\n",
       "      <td>Guacamole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11190</th>\n",
       "      <td>69852</td>\n",
       "      <td>Guacamole</td>\n",
       "      <td>Freebirds</td>\n",
       "      <td>9023340</td>\n",
       "      <td>Female</td>\n",
       "      <td>hypertension, diabetes, heart, obesity</td>\n",
       "      <td>Guacamole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11191</th>\n",
       "      <td>69852</td>\n",
       "      <td>Guacamole</td>\n",
       "      <td>Freebirds</td>\n",
       "      <td>1433326</td>\n",
       "      <td>Female</td>\n",
       "      <td>obesity</td>\n",
       "      <td>Guacamole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11192</th>\n",
       "      <td>69852</td>\n",
       "      <td>Guacamole</td>\n",
       "      <td>Freebirds</td>\n",
       "      <td>3356380</td>\n",
       "      <td>Female</td>\n",
       "      <td>heart</td>\n",
       "      <td>Guacamole</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11193 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       food_id  food_name brand_name  id_user  gender  \\\n",
       "0      2655309      Kebab          0  3847302    Male   \n",
       "1      2655309      Kebab          0  2935940    Male   \n",
       "2      2655309      Kebab          0  5259626    Male   \n",
       "3      2655309      Kebab          0  2097001    Male   \n",
       "4      2655309      Kebab          0  7545290    Male   \n",
       "...        ...        ...        ...      ...     ...   \n",
       "11188    69852  Guacamole  Freebirds  8630293  Female   \n",
       "11189    69852  Guacamole  Freebirds  3959643    Male   \n",
       "11190    69852  Guacamole  Freebirds  9023340  Female   \n",
       "11191    69852  Guacamole  Freebirds  1433326  Female   \n",
       "11192    69852  Guacamole  Freebirds  3356380  Female   \n",
       "\n",
       "                                      disease favoriteFood  \n",
       "0      obesity, diabetes, heart, hypertension        Kebab  \n",
       "1      heart, diabetes, obesity, hypertension        Kebab  \n",
       "2      heart, hypertension, obesity, diabetes        Kebab  \n",
       "3      hypertension, diabetes, heart, obesity        Kebab  \n",
       "4                                    diabetes        Kebab  \n",
       "...                                       ...          ...  \n",
       "11188                            hypertension    Guacamole  \n",
       "11189                diabetes, obesity, heart    Guacamole  \n",
       "11190  hypertension, diabetes, heart, obesity    Guacamole  \n",
       "11191                                 obesity    Guacamole  \n",
       "11192                                   heart    Guacamole  \n",
       "\n",
       "[11193 rows x 7 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = pd.DataFrame()\n",
    "merged_df['food_id'] = raw_merged_df['food_id'].astype(str)\n",
    "merged_df['food_name'] = raw_merged_df['food_name'].astype(str)\n",
    "merged_df['brand_name'] = raw_merged_df['brand_name'].astype(str)\n",
    "merged_df['id_user'] = raw_merged_df['id_user'].astype(str)\n",
    "merged_df['gender'] = raw_merged_df['gender'].astype(str)\n",
    "merged_df['disease'] = raw_merged_df['disease'].apply(\n",
    "    lambda x: ', '.join(x) if isinstance(x, list) else str(x))\n",
    "merged_df['favoriteFood'] = raw_merged_df['favoriteFood'].astype(str)\n",
    "\n",
    "merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_user</th>\n",
       "      <th>gender</th>\n",
       "      <th>disease</th>\n",
       "      <th>favoriteFood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3847302</td>\n",
       "      <td>Male</td>\n",
       "      <td>obesity, diabetes, heart, hypertension</td>\n",
       "      <td>Kebab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2935940</td>\n",
       "      <td>Male</td>\n",
       "      <td>heart, diabetes, obesity, hypertension</td>\n",
       "      <td>Kebab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5259626</td>\n",
       "      <td>Male</td>\n",
       "      <td>heart, hypertension, obesity, diabetes</td>\n",
       "      <td>Kebab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2097001</td>\n",
       "      <td>Male</td>\n",
       "      <td>hypertension, diabetes, heart, obesity</td>\n",
       "      <td>Kebab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7545290</td>\n",
       "      <td>Male</td>\n",
       "      <td>diabetes</td>\n",
       "      <td>Kebab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11188</th>\n",
       "      <td>8630293</td>\n",
       "      <td>Female</td>\n",
       "      <td>hypertension</td>\n",
       "      <td>Guacamole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11189</th>\n",
       "      <td>3959643</td>\n",
       "      <td>Male</td>\n",
       "      <td>diabetes, obesity, heart</td>\n",
       "      <td>Guacamole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11190</th>\n",
       "      <td>9023340</td>\n",
       "      <td>Female</td>\n",
       "      <td>hypertension, diabetes, heart, obesity</td>\n",
       "      <td>Guacamole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11191</th>\n",
       "      <td>1433326</td>\n",
       "      <td>Female</td>\n",
       "      <td>obesity</td>\n",
       "      <td>Guacamole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11192</th>\n",
       "      <td>3356380</td>\n",
       "      <td>Female</td>\n",
       "      <td>heart</td>\n",
       "      <td>Guacamole</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11193 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id_user  gender                                 disease favoriteFood\n",
       "0      3847302    Male  obesity, diabetes, heart, hypertension        Kebab\n",
       "1      2935940    Male  heart, diabetes, obesity, hypertension        Kebab\n",
       "2      5259626    Male  heart, hypertension, obesity, diabetes        Kebab\n",
       "3      2097001    Male  hypertension, diabetes, heart, obesity        Kebab\n",
       "4      7545290    Male                                diabetes        Kebab\n",
       "...        ...     ...                                     ...          ...\n",
       "11188  8630293  Female                            hypertension    Guacamole\n",
       "11189  3959643    Male                diabetes, obesity, heart    Guacamole\n",
       "11190  9023340  Female  hypertension, diabetes, heart, obesity    Guacamole\n",
       "11191  1433326  Female                                 obesity    Guacamole\n",
       "11192  3356380  Female                                   heart    Guacamole\n",
       "\n",
       "[11193 rows x 4 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user = merged_df[['id_user', 'gender', 'disease', 'favoriteFood']]\n",
    "user\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>food_id</th>\n",
       "      <th>food_name</th>\n",
       "      <th>brand_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2655309</td>\n",
       "      <td>Kebab</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2655309</td>\n",
       "      <td>Kebab</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2655309</td>\n",
       "      <td>Kebab</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2655309</td>\n",
       "      <td>Kebab</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2655309</td>\n",
       "      <td>Kebab</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11188</th>\n",
       "      <td>69852</td>\n",
       "      <td>Guacamole</td>\n",
       "      <td>Freebirds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11189</th>\n",
       "      <td>69852</td>\n",
       "      <td>Guacamole</td>\n",
       "      <td>Freebirds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11190</th>\n",
       "      <td>69852</td>\n",
       "      <td>Guacamole</td>\n",
       "      <td>Freebirds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11191</th>\n",
       "      <td>69852</td>\n",
       "      <td>Guacamole</td>\n",
       "      <td>Freebirds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11192</th>\n",
       "      <td>69852</td>\n",
       "      <td>Guacamole</td>\n",
       "      <td>Freebirds</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11193 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       food_id  food_name brand_name\n",
       "0      2655309      Kebab          0\n",
       "1      2655309      Kebab          0\n",
       "2      2655309      Kebab          0\n",
       "3      2655309      Kebab          0\n",
       "4      2655309      Kebab          0\n",
       "...        ...        ...        ...\n",
       "11188    69852  Guacamole  Freebirds\n",
       "11189    69852  Guacamole  Freebirds\n",
       "11190    69852  Guacamole  Freebirds\n",
       "11191    69852  Guacamole  Freebirds\n",
       "11192    69852  Guacamole  Freebirds\n",
       "\n",
       "[11193 rows x 3 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food = merged_df[['food_id', 'food_name', 'brand_name']]\n",
    "food"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = tf.data.Dataset.from_tensor_slices(dict(user))\n",
    "food = tf.data.Dataset.from_tensor_slices(dict(food))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = user.map(lambda x: {\n",
    "    \"id_user\": x[\"id_user\"],\n",
    "    \"gender\": x[\"gender\"],\n",
    "    \"disease\": x[\"disease\"],\n",
    "    \"favoriteFood\": x[\"favoriteFood\"]\n",
    "})\n",
    "\n",
    "food = food.map(lambda x: {\n",
    "    \"food_id\": x[\"food_id\"],\n",
    "    \"food_name\": x[\"food_name\"],\n",
    "    \"brand_name\": x[\"brand_name\"]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_array = []\n",
    "food_array = []\n",
    "for data in user:\n",
    "    user_array.append(data['id_user'].numpy().decode())\n",
    "for data in food:\n",
    "    food_array.append(data['food_id'].numpy().decode())\n",
    "\n",
    "\n",
    "#skills_array = tf.squeeze(skills).numpy().astype(str).tolist()\n",
    "#jobs_array = tf.squeeze(jobs).numpy().astype(str).tolist()\n",
    "\n",
    "user_ids_vocabulary = tf.keras.layers.StringLookup()\n",
    "user_ids_vocabulary.adapt(user_array)\n",
    "\n",
    "food_titles_vocabulary = tf.keras.layers.StringLookup()\n",
    "food_titles_vocabulary.adapt(food_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(tfrs.Model):\n",
    "  # We derive from a custom base class to help reduce boilerplate. Under the hood,\n",
    "  # these are still plain Keras Models.\n",
    "\n",
    "  def __init__(\n",
    "          self,\n",
    "          user_model: tf.keras.Model,\n",
    "          food_model: tf.keras.Model,\n",
    "          task: tfrs.tasks.Retrieval):\n",
    "    super().__init__()\n",
    "\n",
    "    # Set up user and movie representations.\n",
    "    self.user_model = user_model\n",
    "    self.food_model = food_model\n",
    "\n",
    "    # Set up a retrieval task.\n",
    "    self.task = task\n",
    "\n",
    "  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "    # Define how the loss is computed.\n",
    "\n",
    "    user_embeddings = self.user_model(features[\"id_user\"])\n",
    "    food_embeddings = self.food_model(features[\"food_name\"])\n",
    "\n",
    "    return self.task(user_embeddings, food_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define user and movie models.\n",
    "user_model = tf.keras.Sequential([\n",
    "    tf.keras.Input(shape=[], dtype=tf.string, name='id_user'),\n",
    "    user_ids_vocabulary,\n",
    "    tf.keras.layers.Embedding(user_ids_vocabulary.vocabulary_size(), 64)\n",
    "])\n",
    "food_model = tf.keras.Sequential([\n",
    "    tf.keras.Input(shape=[], dtype=tf.string, name='food_id'),\n",
    "    food_titles_vocabulary,\n",
    "    tf.keras.layers.Embedding(food_titles_vocabulary.vocabulary_size(), 64)\n",
    "])\n",
    "\n",
    "# Define your objectives.\n",
    "task = tfrs.tasks.Retrieval(\n",
    "    metrics=tfrs.metrics.FactorizedTopK(\n",
    "        food.batch(128).map(food_model)\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\Ananda\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\Ananda\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Ananda\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\Ananda\\anaconda3\\lib\\site-packages\\tensorflow_recommenders\\models\\base.py\", line 68, in train_step\n        loss = self.compute_loss(inputs, training=True)\n    File \"C:\\Users\\Ananda\\AppData\\Local\\Temp\\ipykernel_7832\\254163675.py\", line 22, in compute_loss\n        user_embeddings = self.user_model(features[\"id_user\"])\n\n    KeyError: 'id_user'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[138], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdagrad(\u001b[39m0.5\u001b[39m))\n\u001b[0;32m      5\u001b[0m \u001b[39m# Train for 3 epochs.\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m model\u001b[39m.\u001b[39;49mfit(food\u001b[39m.\u001b[39;49mbatch(\u001b[39m4096\u001b[39;49m), epochs\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Ananda\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filetdbcc818.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Ananda\\anaconda3\\lib\\site-packages\\tensorflow_recommenders\\models\\base.py:68\u001b[0m, in \u001b[0;36mModel.train_step\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Custom train step using the `compute_loss` method.\"\"\"\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mGradientTape() \u001b[39mas\u001b[39;00m tape:\n\u001b[1;32m---> 68\u001b[0m   loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_loss(inputs, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     70\u001b[0m   \u001b[39m# Handle regularization losses as well.\u001b[39;00m\n\u001b[0;32m     71\u001b[0m   regularization_loss \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlosses)\n",
      "Cell \u001b[1;32mIn[128], line 22\u001b[0m, in \u001b[0;36mModel.compute_loss\u001b[1;34m(self, features, training)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_loss\u001b[39m(\u001b[39mself\u001b[39m, features: Dict[Text, tf\u001b[39m.\u001b[39mTensor], training\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m tf\u001b[39m.\u001b[39mTensor:\n\u001b[0;32m     20\u001b[0m   \u001b[39m# Define how the loss is computed.\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m   user_embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muser_model(features[\u001b[39m\"\u001b[39;49m\u001b[39mid_user\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[0;32m     23\u001b[0m   food_embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfood_model(features[\u001b[39m\"\u001b[39m\u001b[39mfood_name\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m     25\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtask(user_embeddings, food_embeddings)\n",
      "\u001b[1;31mKeyError\u001b[0m: in user code:\n\n    File \"c:\\Users\\Ananda\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\Ananda\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Ananda\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\Ananda\\anaconda3\\lib\\site-packages\\tensorflow_recommenders\\models\\base.py\", line 68, in train_step\n        loss = self.compute_loss(inputs, training=True)\n    File \"C:\\Users\\Ananda\\AppData\\Local\\Temp\\ipykernel_7832\\254163675.py\", line 22, in compute_loss\n        user_embeddings = self.user_model(features[\"id_user\"])\n\n    KeyError: 'id_user'\n"
     ]
    }
   ],
   "source": [
    "# Create a retrieval model.\n",
    "model = Model(user_model, food_model, task)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.5))\n",
    "\n",
    "# Train for 3 epochs.\n",
    "model.fit(food.batch(4096), epochs=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [\n",
    "    tf.feature_column.embedding_column(\n",
    "        tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            \"food_id\", merged_df[\"food_id\"].unique()),\n",
    "        dimension=32\n",
    "    ),\n",
    "    tf.feature_column.embedding_column(\n",
    "        tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            \"food_name\", merged_df[\"food_name\"].unique()),\n",
    "        dimension=32\n",
    "    ),\n",
    "    tf.feature_column.embedding_column(\n",
    "        tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            \"brand_name\", merged_df[\"brand_name\"].unique()),\n",
    "        dimension=16\n",
    "    ),\n",
    "    tf.feature_column.embedding_column(\n",
    "        tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            \"id_user\", merged_df[\"id_user\"].unique()),\n",
    "        dimension=16\n",
    "    ),\n",
    "    tf.feature_column.indicator_column(\n",
    "        tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            \"gender\", merged_df[\"gender\"].unique()),\n",
    "    ),\n",
    "    tf.feature_column.embedding_column(\n",
    "        tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            \"favoriteFood\", merged_df[\"favoriteFood\"].unique()),\n",
    "        dimension=8\n",
    "    ),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[EmbeddingColumn(categorical_column=VocabularyListCategoricalColumn(key='food_id', vocabulary_list=('2655309', '58704864', '68848666', '515347', '1684073', '360970', '51780578', '35362184', '1751238', '59433475', '3451226', '1565707', '855710', '6926210', '50672307', '226469', '54876480', '1277715', '2277254', '6721055', '63385', '5405110', '57008676', '2464847', '195215', '1866283', '22836405', '36346', '94228', '48317129', '1905252', '15766420', '406466', '12173623', '3080414', '372433', '9238078', '7556379', '3310602', '152278', '6708', '110855', '3298228', '13582137', '4689586', '41361247', '30316181', '28343875', '19351319', '16694983', '46783291', '54274347', '12100664', '13385806', '6231843', '59526', '568852', '5569712', '1023391', '1824240', '745530', '4055482', '13753575', '71665', '2960716', '170061', '82162', '91509', '13418168', '69128', '1676706', '1155703', '3249398', '247366', '5777', '69083', '361022', '1460350', '4826631', '5873757', '65437539', '17775578', '14718941', '16308019', '68992145', '29200839', '15040634', '53207165', '65983054', '54882325', '3301', '7561615', '845014', '8145466', '3963638', '5287324', '8652569', '3322351', '2038009', '46397940', '1983417', '38907', '4999900', '177646', '2313527', '297705', '17921832', '25607581', '39974144', '2269188', '284041', '1156118', '40657298', '62699777', '455849', '5796962', '66721634', '45450', '56981952', '25877516', '169779', '2483155', '7290611', '33697', '4142430', '63405', '1297', '12981326', '2618012', '3642507', '390435', '3540', '45463691', '66333074', '4204', '44000121', '38730697', '39059', '4182', '1144637', '1136269', '197013', '103751', '33188702', '1419152', '13888189', '68972', '7240218', '3856', '68781603', '65285360', '29112', '3130609', '19456540', '3375668', '9114981', '20632384', '2752123', '1733141', '10001456', '71688', '12383942', '372825', '849745', '1118455', '4223', '174819', '231241', '3533', '70131', '69128796', '52691464', '68686911', '4560245', '852419', '56681390', '48545486', '3562301', '2413702', '6440247', '49634', '53729729', '66202253', '2249205', '6873471', '2726079', '59061', '46577270', '2643723', '1103988', '10094325', '49731532', '30988149', '1234', '1265964', '68718391', '9657703', '65128124', '28553891', '49584', '74347', '133584', '6712037', '886429', '2681519', '2885525', '101888', '30377667', '10372620', '13528278', '2455091', '3107516', '62438', '13901878', '58409342', '756340', '2669165', '60756', '80081', '2470224', '3801', '5189625', '393287', '2726967', '468685', '153971', '57773', '86137', '4562022', '1493198', '25889792', '3265441', '54329', '5532160', '45072058', '1179532', '19531136', '5076976', '206835', '11488229', '2841740', '5754563', '44025521', '42522863', '6140262', '2664407', '1891079', '9651858', '5362244', '5571', '146991', '8260536', '104005', '5841963', '3882887', '924014', '424378', '127996', '5172456', '591984', '447317', '2125933', '1995633', '99383', '69852'), dtype=tf.string, default_value=-1, num_oov_buckets=0), dimension=32, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x00000117526CEE80>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True, use_safe_embedding_lookup=True),\n",
       " EmbeddingColumn(categorical_column=VocabularyListCategoricalColumn(key='food_name', vocabulary_list=('Kebab', 'Gyoza', 'Chicken Katsu', 'Chicken Cordon Bleu', 'Salmon Teriyaki', 'Fish and Chips', 'Fish Cake', 'Okonomiyaki', 'Coleslaw', 'Ratatouille', 'Kimchi', 'Onion Rings', 'Mashed Potato', 'Risotto', 'Pad Thai', 'Loco Moco', 'Bibimbap', 'Bubur Ayam', 'Japchae', 'Miso Soup', 'Burger Bun', 'Peanut Butter Cookies', 'Baguette', 'Takoyaki', 'Pizza Dough', 'Meringue Cookies', 'Cream Cheese', 'Bagel', 'Puff Pastry', 'Apple Strudel', 'Butter Cookies', 'Lemon Cake', 'Red Velvet', 'French Toast', 'Churros', 'Croissant', 'Cinnamon Roll', 'Chocolate Lava Cake', 'Black Forest', 'Tiramisu', 'Carrot Cake', 'Chocolate Mousse Cake', 'Cloud Bread', 'Samosa', 'Tteokbokki', 'Butterscotch Pudding', 'Thai Tea', 'Guacamole'), dtype=tf.string, default_value=-1, num_oov_buckets=0), dimension=32, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x00000117514DC100>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True, use_safe_embedding_lookup=True),\n",
       " EmbeddingColumn(categorical_column=VocabularyListCategoricalColumn(key='id_user', vocabulary_list=('3847302', '2935940', '5259626', '2097001', '7545290', '4828240', '3213225', '9607150', '2462640', '9917473', '6075146', '3226244', '4789886', '2146810', '8646694', '9881538', '3701394', '9611713', '1795070', '3423432', '7879087', '2483617', '9953879', '4704180', '1432858', '7011989', '7723989', '3119050', '3089090', '5579106', '7781829', '3933537', '6224528', '7385894', '4802315', '7834159', '5718603', '4739883', '3506076', '3423586', '5547530', '9339241', '7539838', '2996817', '4852287', '4254204', '2848667', '1973670', '1302849', '3047501', '6008451', '3134560', '9947852', '7853526', '1259075', '6930051', '5326534', '2576895', '1267729', '8733471', '1549963', '1368250', '4149879', '3356380', '3717984', '6452326', '9287474', '8259903', '1444856', '8024957', '6512001', '1144661', '9330690', '6902111', '3264899', '1351759', '8096878', '6558575', '9335319', '2410150', '9965850', '1729707', '2554294', '2278810', '1098590', '8463058', '7372504', '8258420', '3244661', '2649658', '1048091', '2162784', '3222915', '8671033', '1646568', '7767157', '5517950', '7846859', '2139957', '9371304', '7180405', '9163254', '9882531', '9442004', '9586717', '3915830', '4109904', '9971657', '4398510', '4011729', '4221083', '9909507', '4738736', '4415410', '3959643', '3910164', '7559844', '3523963', '6784817', '9222279', '1241182', '4222693', '8577958', '3242703', '9746280', '4791120', '2912702', '2981193', '4266993', '8896652', '8807718', '2725750', '4001390', '4351980', '8931219', '3494922', '2049174', '7034973', '8145006', '3354132', '1705435', '7588951', '6452843', '6060129', '6742661', '8708516', '2056458', '8474177', '8318625', '7178658', '9545507', '1937257', '4787398', '7529257', '7032444', '9130198', '1641112', '6965690', '9930952', '6726690', '8052047', '2688631', '2028068', '7746140', '7784650', '4252026', '4131116', '7936396', '4964273', '4404624', '4102779', '3376737', '5428160', '8354882', '2013783', '3616897', '6464617', '6478075', '2462245', '2191420', '8653139', '2093446', '9804999', '2433707', '1347226', '9559701', '1668788', '5377239', '5551495', '7648409', '2859010', '1667520', '4488299', '9969729', '4719437', '2582047', '9966917', '1630447', '3543169', '8948277', '2587818', '8679382', '1067153', '2375528', '1130712', '3846484', '4537562', '1373420', '4579797', '4588796', '5826706', '6435966', '4500898', '1792974', '4895731', '8249110', '8861602', '2574151', '7974916', '1458614', '3829285', '5963177', '5417981', '8348616', '6691687', '9349373', '6377269', '9643102', '3503294', '9325188', '9023340', '8560143', '1513964', '5418663', '8617266', '9953405', '8643117', '1031921', '7764231', '2496293', '7030505', '4894367', '1433326', '3975146', '5639269', '7540747', '4444298', '8630293', '5065578', '1557894', '5207825', '8260717', '9926105', '5290090', '7273698', '9002477', '5833357', '6880927', '8912332', '9777160', '6780127', '7724186', '6291595', '1498472', '7849227'), dtype=tf.string, default_value=-1, num_oov_buckets=0), dimension=16, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x00000117514DC700>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True, use_safe_embedding_lookup=True),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='gender', vocabulary_list=('Male', 'Female'), dtype=tf.string, default_value=-1, num_oov_buckets=0))]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a model for users and another for items (foods).\n",
    "# Define the architecture of your user model\n",
    "user_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.DenseFeatures(feature_columns),\n",
    "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Define the architecture of your item model\n",
    "item_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.DenseFeatures(feature_columns),\n",
    "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert user_ids and food_ids to dictionaries.\n",
    "user_ids = {\"user_id\": merged_df[\"id_user\"].values}\n",
    "food_ids = {\"food_id\": merged_df[\"food_id\"].values}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'food_id': <tf.Tensor 'args_0:0' shape=(None,) dtype=string>}. Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"dense_features_13\" \"                 f\"(type DenseFeatures).\n\nFeature food_name is not in features dictionary.\n\nCall arguments received by layer \"dense_features_13\" \"                 f\"(type DenseFeatures):\n  â€¢ features={'food_id': 'tf.Tensor(shape=(None,), dtype=string)'}\n  â€¢ cols_to_output_tensors=None\n  â€¢ training=False",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[99], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Create a retrieval task.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m task \u001b[39m=\u001b[39m tfrs\u001b[39m.\u001b[39mtasks\u001b[39m.\u001b[39mRetrieval(\n\u001b[0;32m      3\u001b[0m     metrics\u001b[39m=\u001b[39mtfrs\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mFactorizedTopK(\n\u001b[1;32m----> 4\u001b[0m         candidates\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mDataset\u001b[39m.\u001b[39;49mfrom_tensor_slices(food_ids)\n\u001b[0;32m      5\u001b[0m         \u001b[39m.\u001b[39;49mbatch(\u001b[39m128\u001b[39;49m)\n\u001b[0;32m      6\u001b[0m         \u001b[39m.\u001b[39;49mmap(item_model)\n\u001b[0;32m      7\u001b[0m     )\n\u001b[0;32m      8\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Ananda\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:2202\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[1;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[0;32m   2199\u001b[0m   \u001b[39mif\u001b[39;00m deterministic \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m DEBUG_MODE:\n\u001b[0;32m   2200\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mThe `deterministic` argument has no effect unless the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2201\u001b[0m                   \u001b[39m\"\u001b[39m\u001b[39m`num_parallel_calls` argument is specified.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 2202\u001b[0m   \u001b[39mreturn\u001b[39;00m MapDataset(\u001b[39mself\u001b[39;49m, map_func, preserve_cardinality\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m   2203\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2204\u001b[0m   \u001b[39mreturn\u001b[39;00m ParallelMapDataset(\n\u001b[0;32m   2205\u001b[0m       \u001b[39mself\u001b[39m,\n\u001b[0;32m   2206\u001b[0m       map_func,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2209\u001b[0m       preserve_cardinality\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m   2210\u001b[0m       name\u001b[39m=\u001b[39mname)\n",
      "File \u001b[1;32mc:\\Users\\Ananda\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:5400\u001b[0m, in \u001b[0;36mMapDataset.__init__\u001b[1;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[0;32m   5398\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_use_inter_op_parallelism \u001b[39m=\u001b[39m use_inter_op_parallelism\n\u001b[0;32m   5399\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_preserve_cardinality \u001b[39m=\u001b[39m preserve_cardinality\n\u001b[1;32m-> 5400\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_func \u001b[39m=\u001b[39m structured_function\u001b[39m.\u001b[39;49mStructuredFunctionWrapper(\n\u001b[0;32m   5401\u001b[0m     map_func,\n\u001b[0;32m   5402\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transformation_name(),\n\u001b[0;32m   5403\u001b[0m     dataset\u001b[39m=\u001b[39;49minput_dataset,\n\u001b[0;32m   5404\u001b[0m     use_legacy_function\u001b[39m=\u001b[39;49muse_legacy_function)\n\u001b[0;32m   5405\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name \u001b[39m=\u001b[39m name\n\u001b[0;32m   5406\u001b[0m variant_tensor \u001b[39m=\u001b[39m gen_dataset_ops\u001b[39m.\u001b[39mmap_dataset(\n\u001b[0;32m   5407\u001b[0m     input_dataset\u001b[39m.\u001b[39m_variant_tensor,  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   5408\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_func\u001b[39m.\u001b[39mfunction\u001b[39m.\u001b[39mcaptured_inputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5411\u001b[0m     preserve_cardinality\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_preserve_cardinality,\n\u001b[0;32m   5412\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_common_args)\n",
      "File \u001b[1;32mc:\\Users\\Ananda\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:271\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[1;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[0;32m    264\u001b[0m       warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    265\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    266\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    267\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    268\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    269\u001b[0m     fn_factory \u001b[39m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[1;32m--> 271\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function \u001b[39m=\u001b[39m fn_factory()\n\u001b[0;32m    272\u001b[0m \u001b[39m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[0;32m    273\u001b[0m add_to_graph \u001b[39m&\u001b[39m\u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[1;32mc:\\Users\\Ananda\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2610\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2601\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_concrete_function\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m   2602\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Returns a `ConcreteFunction` specialized to inputs and execution context.\u001b[39;00m\n\u001b[0;32m   2603\u001b[0m \n\u001b[0;32m   2604\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2608\u001b[0m \u001b[39m       or `tf.Tensor` or `tf.TensorSpec`.\u001b[39;00m\n\u001b[0;32m   2609\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2610\u001b[0m   graph_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_concrete_function_garbage_collected(\n\u001b[0;32m   2611\u001b[0m       \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   2612\u001b[0m   graph_function\u001b[39m.\u001b[39m_garbage_collector\u001b[39m.\u001b[39mrelease()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   2613\u001b[0m   \u001b[39mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32mc:\\Users\\Ananda\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2576\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2574\u001b[0m   args, kwargs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   2575\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m-> 2576\u001b[0m   graph_function, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n\u001b[0;32m   2577\u001b[0m   seen_names \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n\u001b[0;32m   2578\u001b[0m   captured \u001b[39m=\u001b[39m object_identity\u001b[39m.\u001b[39mObjectIdentitySet(\n\u001b[0;32m   2579\u001b[0m       graph_function\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39minternal_captures)\n",
      "File \u001b[1;32mc:\\Users\\Ananda\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2760\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2758\u001b[0m   \u001b[39m# Only get placeholders for arguments, not captures\u001b[39;00m\n\u001b[0;32m   2759\u001b[0m   args, kwargs \u001b[39m=\u001b[39m placeholder_dict[\u001b[39m\"\u001b[39m\u001b[39margs\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m-> 2760\u001b[0m graph_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_graph_function(args, kwargs)\n\u001b[0;32m   2762\u001b[0m graph_capture_container \u001b[39m=\u001b[39m graph_function\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39m_capture_func_lib  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   2763\u001b[0m \u001b[39m# Maintain the list of all captures\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Ananda\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2670\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2665\u001b[0m missing_arg_names \u001b[39m=\u001b[39m [\n\u001b[0;32m   2666\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (arg, i) \u001b[39mfor\u001b[39;00m i, arg \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(missing_arg_names)\n\u001b[0;32m   2667\u001b[0m ]\n\u001b[0;32m   2668\u001b[0m arg_names \u001b[39m=\u001b[39m base_arg_names \u001b[39m+\u001b[39m missing_arg_names\n\u001b[0;32m   2669\u001b[0m graph_function \u001b[39m=\u001b[39m ConcreteFunction(\n\u001b[1;32m-> 2670\u001b[0m     func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[0;32m   2671\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name,\n\u001b[0;32m   2672\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_function,\n\u001b[0;32m   2673\u001b[0m         args,\n\u001b[0;32m   2674\u001b[0m         kwargs,\n\u001b[0;32m   2675\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_signature,\n\u001b[0;32m   2676\u001b[0m         autograph\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph,\n\u001b[0;32m   2677\u001b[0m         autograph_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph_options,\n\u001b[0;32m   2678\u001b[0m         arg_names\u001b[39m=\u001b[39;49marg_names,\n\u001b[0;32m   2679\u001b[0m         capture_by_value\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_capture_by_value),\n\u001b[0;32m   2680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_attributes,\n\u001b[0;32m   2681\u001b[0m     spec\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_spec,\n\u001b[0;32m   2682\u001b[0m     \u001b[39m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[0;32m   2683\u001b[0m     \u001b[39m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[0;32m   2684\u001b[0m     \u001b[39m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[0;32m   2685\u001b[0m     \u001b[39m# ConcreteFunction.\u001b[39;00m\n\u001b[0;32m   2686\u001b[0m     shared_func_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m   2687\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32mc:\\Users\\Ananda\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1247\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1244\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1245\u001b[0m   _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[1;32m-> 1247\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39mfunc_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfunc_kwargs)\n\u001b[0;32m   1249\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1250\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1251\u001b[0m func_outputs \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mmap_structure(\n\u001b[0;32m   1252\u001b[0m     convert, func_outputs, expand_composites\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Ananda\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:248\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[39m@eager_function\u001b[39m\u001b[39m.\u001b[39mdefun_with_attributes(\n\u001b[0;32m    243\u001b[0m     input_signature\u001b[39m=\u001b[39mstructure\u001b[39m.\u001b[39mget_flat_tensor_specs(\n\u001b[0;32m    244\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_structure),\n\u001b[0;32m    245\u001b[0m     autograph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    246\u001b[0m     attributes\u001b[39m=\u001b[39mdefun_kwargs)\n\u001b[0;32m    247\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_fn\u001b[39m(\u001b[39m*\u001b[39margs):  \u001b[39m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[1;32m--> 248\u001b[0m   ret \u001b[39m=\u001b[39m wrapper_helper(\u001b[39m*\u001b[39;49margs)\n\u001b[0;32m    249\u001b[0m   ret \u001b[39m=\u001b[39m structure\u001b[39m.\u001b[39mto_tensor_list(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_structure, ret)\n\u001b[0;32m    250\u001b[0m   \u001b[39mreturn\u001b[39;00m [ops\u001b[39m.\u001b[39mconvert_to_tensor(t) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m ret]\n",
      "File \u001b[1;32mc:\\Users\\Ananda\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:177\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _should_unpack(nested_args):\n\u001b[0;32m    176\u001b[0m   nested_args \u001b[39m=\u001b[39m (nested_args,)\n\u001b[1;32m--> 177\u001b[0m ret \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39;49mtf_convert(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func, ag_ctx)(\u001b[39m*\u001b[39;49mnested_args)\n\u001b[0;32m    178\u001b[0m \u001b[39mif\u001b[39;00m _should_pack(ret):\n\u001b[0;32m    179\u001b[0m   ret \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(ret)\n",
      "File \u001b[1;32mc:\\Users\\Ananda\\anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    688\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[1;32m--> 689\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[0;32m    690\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    691\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Ananda\\anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    374\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    376\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39muser_requested \u001b[39mand\u001b[39;00m conversion\u001b[39m.\u001b[39mis_allowlisted(f):\n\u001b[1;32m--> 377\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    379\u001b[0m \u001b[39m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[39m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[39m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \u001b[39m# things like builtins.\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[1;32mc:\\Users\\Ananda\\anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:458\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    455\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[0;32m    457\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 458\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    459\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[1;32mc:\\Users\\Ananda\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Ananda\\anaconda3\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:2440\u001b[0m, in \u001b[0;36mFeatureTransformationCache.get\u001b[1;34m(self, key, state_manager, training)\u001b[0m\n\u001b[0;32m   2437\u001b[0m   \u001b[39mreturn\u001b[39;00m feature_tensor\n\u001b[0;32m   2439\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, six\u001b[39m.\u001b[39mstring_types):\n\u001b[1;32m-> 2440\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mFeature \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m is not in features dictionary.\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(key))\n\u001b[0;32m   2442\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(key, FeatureColumn):\n\u001b[0;32m   2443\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mkey\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m must be either a \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mstr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m or \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFeatureColumn\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   2444\u001b[0m                   \u001b[39m'\u001b[39m\u001b[39mProvided: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(key))\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer \"dense_features_13\" \"                 f\"(type DenseFeatures).\n\nFeature food_name is not in features dictionary.\n\nCall arguments received by layer \"dense_features_13\" \"                 f\"(type DenseFeatures):\n  â€¢ features={'food_id': 'tf.Tensor(shape=(None,), dtype=string)'}\n  â€¢ cols_to_output_tensors=None\n  â€¢ training=False"
     ]
    }
   ],
   "source": [
    "# Create a retrieval task.\n",
    "task = tfrs.tasks.Retrieval(\n",
    "    metrics=tfrs.metrics.FactorizedTopK(\n",
    "        candidates=tf.data.Dataset.from_tensor_slices(food_ids)\n",
    "        .batch(128)\n",
    "        .map(item_model)\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'task' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Combine them into a recommendation model.\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model \u001b[39m=\u001b[39m tfrs\u001b[39m.\u001b[39mModel(user_model\u001b[39m=\u001b[39muser_model, item_model\u001b[39m=\u001b[39mitem_model, task\u001b[39m=\u001b[39mtask)\n\u001b[0;32m      4\u001b[0m \u001b[39m# Make a dataset of (user, item) pairs.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m dataset \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataset\u001b[39m.\u001b[39mfrom_tensor_slices((user_ids, food_ids))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'task' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Combine them into a recommendation model.\n",
    "model = tfrs.Model(user_model=user_model, item_model=item_model, task=task)\n",
    "\n",
    "# Make a dataset of (user, item) pairs.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((user_ids, food_ids))\n",
    "dataset = dataset.shuffle(len(merged_df)).batch(\n",
    "    128).cache().prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# Fit the model.\n",
    "model.fit(dataset, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'item_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[76], line 12\u001b[0m\n\u001b[0;32m      7\u001b[0m food_ids \u001b[39m=\u001b[39m merged_df[\u001b[39m\"\u001b[39m\u001b[39mfood_id\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mvalues\n\u001b[0;32m      9\u001b[0m \u001b[39m# Create a retrieval task.\u001b[39;00m\n\u001b[0;32m     10\u001b[0m task \u001b[39m=\u001b[39m tfrs\u001b[39m.\u001b[39mtasks\u001b[39m.\u001b[39mRetrieval(\n\u001b[0;32m     11\u001b[0m     metrics\u001b[39m=\u001b[39mtfrs\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mFactorizedTopK(\n\u001b[1;32m---> 12\u001b[0m         candidates\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataset\u001b[39m.\u001b[39mfrom_tensor_slices(food_ids)\u001b[39m.\u001b[39mbatch(\u001b[39m128\u001b[39m)\u001b[39m.\u001b[39mmap(item_model)\n\u001b[0;32m     13\u001b[0m     )\n\u001b[0;32m     14\u001b[0m )\n\u001b[0;32m     16\u001b[0m \u001b[39m# Define a model for users and another for items (foods).\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[39m# Define the architecture of your user model\u001b[39;00m\n\u001b[0;32m     18\u001b[0m user_model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mSequential([\n\u001b[0;32m     19\u001b[0m     tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDenseFeatures(feature_columns),\n\u001b[0;32m     20\u001b[0m     tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(\u001b[39m128\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     24\u001b[0m     tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(\u001b[39m1\u001b[39m)\n\u001b[0;32m     25\u001b[0m ])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'item_model' is not defined"
     ]
    }
   ],
   "source": [
    "# TFRS imports.\n",
    "import tensorflow_recommenders as tfrs\n",
    "\n",
    "# Assume user_ids and food_ids are the relevant columns.\n",
    "# Convert these to tensors.\n",
    "user_ids = tf.constant(merged_df[\"id_user\"])\n",
    "food_ids = tf.constant(merged_df[\"food_id\"])\n",
    "\n",
    "# Create a retrieval task.\n",
    "task = tfrs.tasks.Retrieval(\n",
    "    metrics=tfrs.metrics.FactorizedTopK(\n",
    "        candidates=food_ids.batch(128).map(item_model)\n",
    "    )\n",
    ")\n",
    "\n",
    "# Define a model for users and another for items (foods).\n",
    "# define the architecture of your user model\n",
    "user_model = tf.keras.Sequential(tf.keras.layers.DenseFeatures(feature_columns),\n",
    "                                 tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "                                 tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "                                 tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "                                 tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "                                 tf.keras.layers.Dense(1))\n",
    "# define the architecture of your item model\n",
    "item_model = tf.keras.Sequential(tf.keras.layers.DenseFeatures(feature_columns),\n",
    "                                 tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "                                 tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "                                 tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "                                 tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "                                 tf.keras.layers.Dense(1))\n",
    "\n",
    "# Combine them into a recommendation model.\n",
    "model = tfrs.Model(user_model=user_model, item_model=item_model, task=task)\n",
    "\n",
    "# Train.\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
    "\n",
    "# Make a dataset of (user, item) pairs.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((user_ids, food_ids))\n",
    "dataset = dataset.batch(128).cache().prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# Assume user_ids and food_ids are the relevant columns.\n",
    "dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (merged_df[\"user_id\"].values, merged_df[\"food_id\"].values))\n",
    "\n",
    "# Shuffle and batch the dataset.\n",
    "batch_size = 128\n",
    "dataset = dataset.shuffle(len(merged_df)).batch(\n",
    "    batch_size).cache().prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# Fit the model.\n",
    "model.fit(dataset, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'food_id': <tf.Tensor 'IteratorGetNext:12' shape=(None,) dtype=string>, 'food_name': <tf.Tensor 'IteratorGetNext:13' shape=(None,) dtype=string>, 'food_type': <tf.Tensor 'IteratorGetNext:14' shape=(None,) dtype=string>, 'food_url': <tf.Tensor 'IteratorGetNext:15' shape=(None,) dtype=string>, 'brand_name': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>, 'calcium': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float64>, 'calories': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float64>, 'carbohydrate': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float64>, 'cholesterol': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float64>, 'fat': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float64>, 'fiber': <tf.Tensor 'IteratorGetNext:11' shape=(None,) dtype=float64>, 'iron': <tf.Tensor 'IteratorGetNext:20' shape=(None,) dtype=float64>, 'measurement_description': <tf.Tensor 'IteratorGetNext:21' shape=(None,) dtype=string>, 'metric_serving_amount': <tf.Tensor 'IteratorGetNext:22' shape=(None,) dtype=float64>, 'metric_serving_unit': <tf.Tensor 'IteratorGetNext:23' shape=(None,) dtype=string>, 'monounsaturated_fat': <tf.Tensor 'IteratorGetNext:24' shape=(None,) dtype=float64>, 'number_of_units': <tf.Tensor 'IteratorGetNext:25' shape=(None,) dtype=float64>, 'polyunsaturated_fat': <tf.Tensor 'IteratorGetNext:26' shape=(None,) dtype=float64>, 'potassium': <tf.Tensor 'IteratorGetNext:27' shape=(None,) dtype=float64>, 'protein': <tf.Tensor 'IteratorGetNext:28' shape=(None,) dtype=float64>, 'saturated_fat': <tf.Tensor 'IteratorGetNext:29' shape=(None,) dtype=float64>, 'serving_description': <tf.Tensor 'IteratorGetNext:30' shape=(None,) dtype=string>, 'serving_id': <tf.Tensor 'IteratorGetNext:31' shape=(None,) dtype=string>, 'serving_url': <tf.Tensor 'IteratorGetNext:32' shape=(None,) dtype=string>, 'sodium': <tf.Tensor 'IteratorGetNext:33' shape=(None,) dtype=float64>, 'sugar': <tf.Tensor 'IteratorGetNext:34' shape=(None,) dtype=float64>, 'trans_fat': <tf.Tensor 'IteratorGetNext:35' shape=(None,) dtype=float64>, 'vitamin_a': <tf.Tensor 'IteratorGetNext:36' shape=(None,) dtype=float64>, 'vitamin_c': <tf.Tensor 'IteratorGetNext:37' shape=(None,) dtype=float64>, 'added_sugars': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float64>, 'vitamin_d': <tf.Tensor 'IteratorGetNext:38' shape=(None,) dtype=float64>, 'gender': <tf.Tensor 'IteratorGetNext:16' shape=(None,) dtype=string>, 'weight': <tf.Tensor 'IteratorGetNext:39' shape=(None,) dtype=float64>, 'id_user': <tf.Tensor 'IteratorGetNext:19' shape=(None,) dtype=string>, 'activityLevel': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'goals': <tf.Tensor 'IteratorGetNext:17' shape=(None,) dtype=string>, 'height': <tf.Tensor 'IteratorGetNext:18' shape=(None,) dtype=string>, 'disease': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=string>, 'favoriteFood': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=string>, 'birthdate': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>}. Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\Ananda\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\Ananda\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Ananda\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\Ananda\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 995, in train_step\n        self._validate_target_and_loss(y, loss)\n    File \"c:\\Users\\Ananda\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 949, in _validate_target_and_loss\n        raise ValueError(\n\n    ValueError: Target data is missing. Your model was compiled with loss=<keras.losses.MeanSquaredError object at 0x00000285853C6130>, and therefore expects target data to be provided in `fit()`.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[69], line 34\u001b[0m\n\u001b[0;32m     30\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdagrad(\n\u001b[0;32m     31\u001b[0m     learning_rate\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m), loss\u001b[39m=\u001b[39mloss)\n\u001b[0;32m     33\u001b[0m \u001b[39m# Train the model with the TensorFlow Dataset\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m model\u001b[39m.\u001b[39;49mfit(dataset, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Ananda\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filetdu6jqts.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\Ananda\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\Ananda\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Ananda\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\Ananda\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 995, in train_step\n        self._validate_target_and_loss(y, loss)\n    File \"c:\\Users\\Ananda\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 949, in _validate_target_and_loss\n        raise ValueError(\n\n    ValueError: Target data is missing. Your model was compiled with loss=<keras.losses.MeanSquaredError object at 0x00000285853C6130>, and therefore expects target data to be provided in `fit()`.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Convert the Pandas DataFrame to a TensorFlow Dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices(dict(merged_df))\n",
    "\n",
    "# Shuffle and batch the dataset (adjust the batch_size as needed)\n",
    "batch_size = 32\n",
    "dataset = dataset.shuffle(len(merged_df)).batch(batch_size)\n",
    "\n",
    "# Create an instance of the retrieval task\n",
    "task = tfrs.tasks.Retrieval(\n",
    "    metrics=tfrs.metrics.FactorizedTopK(\n",
    "        candidates=merged_df[\"food_id\"].unique().tolist()\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create an instance of the TFRS model and compile it\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.DenseFeatures(feature_columns),\n",
    "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "loss = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(\n",
    "    learning_rate=0.1), loss=loss)\n",
    "\n",
    "# Train the model with the TensorFlow Dataset\n",
    "model.fit(dataset, epochs=10, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'task' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 92\u001b[0m\n\u001b[0;32m      7\u001b[0m feature_columns \u001b[39m=\u001b[39m [\n\u001b[0;32m      8\u001b[0m     tf\u001b[39m.\u001b[39mfeature_column\u001b[39m.\u001b[39membedding_column(\n\u001b[0;32m      9\u001b[0m         tf\u001b[39m.\u001b[39mfeature_column\u001b[39m.\u001b[39mcategorical_column_with_vocabulary_list(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     87\u001b[0m     )\n\u001b[0;32m     88\u001b[0m ]\n\u001b[0;32m     90\u001b[0m \u001b[39m# Create an instance of the TFRS model and compile it\u001b[39;00m\n\u001b[0;32m     91\u001b[0m model \u001b[39m=\u001b[39m tfrs\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mFactorizedTopK(\n\u001b[1;32m---> 92\u001b[0m     model\u001b[39m=\u001b[39mtfrs\u001b[39m.\u001b[39mtasks\u001b[39m.\u001b[39mRetrieval(task))\n\u001b[0;32m     94\u001b[0m \u001b[39m# Train the model with the feature columns\u001b[39;00m\n\u001b[0;32m     95\u001b[0m model\u001b[39m.\u001b[39mfit(merged_df, epochs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'task' is not defined"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "\n",
    "merged_df[\"disease\"] = merged_df[\"disease\"].apply(lambda x: ', '.join(x))\n",
    "\n",
    "# Define the feature columns\n",
    "feature_columns = [\n",
    "    tf.feature_column.embedding_column(\n",
    "        tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            \"food_id\", merged_df[\"food_id\"].unique()),\n",
    "        dimension=32\n",
    "    ),\n",
    "    tf.feature_column.embedding_column(\n",
    "        tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            \"food_name\", merged_df[\"food_name\"].unique()),\n",
    "        dimension=32\n",
    "    ),\n",
    "    tf.feature_column.embedding_column(\n",
    "        tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            \"food_type\", merged_df[\"food_type\"].unique()),\n",
    "        dimension=8\n",
    "    ),\n",
    "    tf.feature_column.embedding_column(\n",
    "        tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            \"brand_name\", merged_df[\"brand_name\"].unique()),\n",
    "        dimension=16\n",
    "    ),\n",
    "    tf.feature_column.numeric_column(\"calcium\"),\n",
    "    tf.feature_column.numeric_column(\"calories\"),\n",
    "    tf.feature_column.numeric_column(\"carbohydrate\"),\n",
    "    tf.feature_column.numeric_column(\"cholesterol\"),\n",
    "    tf.feature_column.numeric_column(\"fat\"),\n",
    "    tf.feature_column.numeric_column(\"fiber\"),\n",
    "    tf.feature_column.numeric_column(\"iron\"),\n",
    "    tf.feature_column.embedding_column(\n",
    "        tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            \"measurement_description\", merged_df[\"measurement_description\"].unique()),\n",
    "        dimension=8\n",
    "    ),\n",
    "    tf.feature_column.numeric_column(\"metric_serving_amount\"),\n",
    "    tf.feature_column.embedding_column(\n",
    "        tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            \"metric_serving_unit\", merged_df[\"metric_serving_unit\"].unique()),\n",
    "        dimension=8\n",
    "    ),\n",
    "    tf.feature_column.numeric_column(\"monounsaturated_fat\"),\n",
    "    tf.feature_column.numeric_column(\"number_of_units\"),\n",
    "    tf.feature_column.numeric_column(\"polyunsaturated_fat\"),\n",
    "    tf.feature_column.numeric_column(\"potassium\"),\n",
    "    tf.feature_column.numeric_column(\"protein\"),\n",
    "    tf.feature_column.numeric_column(\"saturated_fat\"),\n",
    "    tf.feature_column.embedding_column(\n",
    "        tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            \"serving_description\", merged_df[\"serving_description\"].unique()),\n",
    "        dimension=8\n",
    "    ),\n",
    "    tf.feature_column.embedding_column(\n",
    "        tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            \"serving_id\", merged_df[\"serving_id\"].unique()),\n",
    "        dimension=32\n",
    "    ),\n",
    "    tf.feature_column.embedding_column(\n",
    "        tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            \"favoriteFood\", merged_df[\"favoriteFood\"].unique()),\n",
    "        dimension=8\n",
    "    ),\n",
    "    tf.feature_column.embedding_column(\n",
    "        tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            \"birthdate\", merged_df[\"birthdate\"].unique()),\n",
    "        dimension=16\n",
    "    ),\n",
    "    tf.feature_column.embedding_column(\n",
    "        tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            \"gender\", merged_df[\"gender\"].unique()),\n",
    "        dimension=8\n",
    "    ),\n",
    "    tf.feature_column.numeric_column(\"weight\"),\n",
    "    tf.feature_column.embedding_column(\n",
    "        tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            \"goals\", merged_df[\"goals\"].unique()),\n",
    "        dimension=8\n",
    "    ),\n",
    "    tf.feature_column.embedding_column(\n",
    "        tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            \"disease\", merged_df[\"disease\"].unique().astype(str)),\n",
    "        dimension=8\n",
    "    )\n",
    "]\n",
    "\n",
    "# Create an instance of the TFRS model and compile it\n",
    "model = tfrs.metrics.FactorizedTopK(\n",
    "    model=tfrs.tasks.Retrieval(task))\n",
    "\n",
    "# Train the model with the feature columns\n",
    "model.fit(merged_df, epochs=10, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert columns to appropriate data types\n",
    "merged_df['food_id'] = merged_df['food_id'].astype(str)\n",
    "merged_df['food_name'] = merged_df['food_name'].astype(str)\n",
    "merged_df['food_type'] = merged_df['food_type'].astype(str)\n",
    "merged_df['food_url'] = merged_df['food_url'].astype(str)\n",
    "merged_df['brand_name'] = merged_df['brand_name'].astype(str)\n",
    "merged_df['calcium'] = merged_df['calcium'].astype(float)\n",
    "merged_df['calories'] = merged_df['calories'].astype(float)\n",
    "merged_df['carbohydrate'] = merged_df['carbohydrate'].astype(float)\n",
    "merged_df['cholesterol'] = merged_df['cholesterol'].astype(float)\n",
    "merged_df['fat'] = merged_df['fat'].astype(float)\n",
    "merged_df['fiber'] = merged_df['fiber'].astype(float)\n",
    "merged_df['iron'] = merged_df['iron'].astype(float)\n",
    "merged_df['measurement_description'] = merged_df['measurement_description'].astype(\n",
    "    str)\n",
    "merged_df['metric_serving_amount'] = merged_df['metric_serving_amount'].astype(\n",
    "    float)\n",
    "merged_df['metric_serving_unit'] = merged_df['metric_serving_unit'].astype(str)\n",
    "merged_df['monounsaturated_fat'] = merged_df['monounsaturated_fat'].astype(\n",
    "    float)\n",
    "merged_df['number_of_units'] = merged_df['number_of_units'].astype(float)\n",
    "merged_df['polyunsaturated_fat'] = merged_df['polyunsaturated_fat'].astype(\n",
    "    float)\n",
    "merged_df['potassium'] = merged_df['potassium'].astype(float)\n",
    "merged_df['protein'] = merged_df['protein'].astype(float)\n",
    "merged_df['saturated_fat'] = merged_df['saturated_fat'].astype(float)\n",
    "merged_df['serving_description'] = merged_df['serving_description'].astype(str)\n",
    "merged_df['serving_id'] = merged_df['serving_id'].astype(str)\n",
    "merged_df['serving_url'] = merged_df['serving_url'].astype(str)\n",
    "merged_df['sodium'] = merged_df['sodium'].astype(float)\n",
    "merged_df['sugar'] = merged_df['sugar'].astype(float)\n",
    "merged_df['trans_fat'] = merged_df['trans_fat'].astype(float)\n",
    "merged_df['vitamin_a'] = merged_df['vitamin_a'].astype(float)\n",
    "merged_df['vitamin_c'] = merged_df['vitamin_c'].astype(float)\n",
    "merged_df['added_sugars'] = merged_df['added_sugars'].astype(float)\n",
    "merged_df['vitamin_d'] = merged_df['vitamin_d'].astype(float)\n",
    "merged_df['gender'] = merged_df['gender'].astype(str)\n",
    "merged_df['weight'] = merged_df['weight'].astype(float)\n",
    "merged_df['id_user'] = merged_df['id_user'].astype(str)\n",
    "merged_df['activityLevel'] = merged_df['activityLevel'].astype(str)\n",
    "merged_df['goals'] = merged_df['goals'].astype(str)\n",
    "merged_df['height'] = merged_df['height'].astype(str)\n",
    "merged_df['disease'] = merged_df['disease']\n",
    "merged_df['favoriteFood'] = merged_df['favoriteFood'].astype(str)\n",
    "merged_df['birthdate'] = merged_df['birthdate'].astype(str)\n",
    "\n",
    "# Define the feature columns\n",
    "feature_columns = [\n",
    "    tf.feature_column.embedding_column(\n",
    "        tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            \"food_id\", merged_df[\"food_id\"].unique()),\n",
    "        dimension=32\n",
    "    ),\n",
    "    tf.feature_column.embedding_column(\n",
    "        tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            \"food_name\", merged_df[\"food_name\"].unique()),\n",
    "        dimension=32\n",
    "    ),\n",
    "    tf.feature_column.embedding_column(\n",
    "        tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            \"food_type\", merged_df[\"food_type\"].unique()),\n",
    "        dimension=8\n",
    "    ),\n",
    "    tf.feature_column.embedding_column(\n",
    "        tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            \"brand_name\", merged_df[\"brand_name\"].unique()),\n",
    "        dimension=16\n",
    "    ),\n",
    "    tf.feature_column.numeric_column(\"calcium\"),\n",
    "    tf.feature_column.numeric_column(\"calories\"),\n",
    "    tf.feature_column.numeric_column(\"carbohydrate\"),\n",
    "    tf.feature_column.numeric_column(\"cholesterol\"),\n",
    "    tf.feature_column.numeric_column(\"fat\"),\n",
    "    tf.feature_column.numeric_column(\"fiber\"),\n",
    "    tf.feature_column.numeric_column(\"iron\"),\n",
    "    tf.feature_column.embedding_column(\n",
    "        tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            \"measurement_description\", merged_df[\"measurement_description\"].unique()),\n",
    "        dimension=8\n",
    "    ),\n",
    "    tf.feature_column.numeric_column(\"metric_serving_amount\"),\n",
    "    tf.feature_column.embedding_column(\n",
    "        tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            \"metric_serving_unit\", merged_df[\"metric_serving_unit\"].unique()),\n",
    "        dimension=8\n",
    "    ),\n",
    "    tf.feature_column.numeric_column(\"monounsaturated_fat\"),\n",
    "    tf.feature_column.numeric_column(\"number_of_units\"),\n",
    "    tf.feature_column.numeric_column(\"polyunsaturated_fat\"),\n",
    "    tf.feature_column.numeric_column(\"potassium\"),\n",
    "    tf.feature_column.numeric_column(\"protein\"),\n",
    "    tf.feature_column.numeric_column(\"saturated_fat\"),\n",
    "    tf.feature_column.embedding_column(\n",
    "        tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            \"serving_description\", merged_df[\"serving_description\"].unique()),\n",
    "        dimension=8\n",
    "    ),\n",
    "    tf.feature_column.embedding_column(\n",
    "        tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            \"serving_id\", merged_df[\"serving_id\"].unique()),\n",
    "        dimension=32\n",
    "    ),\n",
    "    tf.feature_column.embedding_column(\n",
    "        tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            \"favoriteFood\", merged_df[\"favoriteFood\"].unique()),\n",
    "        dimension=8\n",
    "    ),\n",
    "    tf.feature_column.embedding_column(\n",
    "        tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            \"birthdate\", merged_df[\"birthdate\"].unique()),\n",
    "        dimension=16\n",
    "    ),\n",
    "    tf.feature_column.embedding_column(\n",
    "        tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            \"gender\", merged_df[\"gender\"].unique()),\n",
    "        dimension=8\n",
    "    ),\n",
    "    tf.feature_column.numeric_column(\"weight\"),\n",
    "    tf.feature_column.embedding_column(\n",
    "        tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            \"goals\", merged_df[\"goals\"].unique()),\n",
    "        dimension=8\n",
    "    ),\n",
    "    tf.feature_column.embedding_column(\n",
    "        tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            \"disease\", merged_df[\"disease\"].unique()),\n",
    "        dimension=8\n",
    "    )\n",
    "]\n",
    "\n",
    "# Create an instance of the retrieval task\n",
    "task = tfrs.tasks.Retrieval(\n",
    "    metrics=tfrs.metrics.FactorizedTopK(\n",
    "        candidates=merged_df[\"food_id\"].unique().tolist()\n",
    "    )\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[EmbeddingColumn(categorical_column=VocabularyListCategoricalColumn(key='food_id', vocabulary_list=('2655309', '58704864', '68848666', '515347', '1684073', '360970', '51780578', '35362184', '1751238', '59433475', '3451226', '1565707', '855710', '6926210', '50672307', '226469', '54876480', '1277715', '2277254', '6721055', '63385', '5405110', '57008676', '2464847', '195215', '1866283', '22836405', '36346', '94228', '48317129', '1905252', '15766420', '406466', '12173623', '3080414', '372433', '9238078', '7556379', '3310602', '152278', '6708', '110855', '3298228', '13582137', '4689586', '41361247', '30316181', '28343875', '19351319', '16694983', '46783291', '54274347', '12100664', '13385806', '6231843', '59526', '568852', '5569712', '1023391', '1824240', '745530', '4055482', '13753575', '71665', '2960716', '170061', '82162', '91509', '13418168', '69128', '1676706', '1155703', '3249398', '247366', '5777', '69083', '361022', '1460350', '4826631', '5873757', '65437539', '17775578', '14718941', '16308019', '68992145', '29200839', '15040634', '53207165', '65983054', '54882325', '3301', '7561615', '845014', '8145466', '3963638', '5287324', '8652569', '3322351', '2038009', '46397940', '1983417', '38907', '4999900', '177646', '2313527', '297705', '17921832', '25607581', '39974144', '2269188', '284041', '1156118', '40657298', '62699777', '455849', '5796962', '66721634', '45450', '56981952', '25877516', '169779', '2483155', '7290611', '33697', '4142430', '63405', '1297', '12981326', '2618012', '3642507', '390435', '3540', '45463691', '66333074', '4204', '44000121', '38730697', '39059', '4182', '1144637', '1136269', '197013', '103751', '33188702', '1419152', '13888189', '68972', '7240218', '3856', '68781603', '65285360', '29112', '3130609', '19456540', '3375668', '9114981', '20632384', '2752123', '1733141', '10001456', '71688', '12383942', '372825', '849745', '1118455', '4223', '174819', '231241', '3533', '70131', '69128796', '52691464', '68686911', '4560245', '852419', '56681390', '48545486', '3562301', '2413702', '6440247', '49634', '53729729', '66202253', '2249205', '6873471', '2726079', '59061', '46577270', '2643723', '1103988', '10094325', '49731532', '30988149', '1234', '1265964', '68718391', '9657703', '65128124', '28553891', '49584', '74347', '133584', '6712037', '886429', '2681519', '2885525', '101888', '30377667', '10372620', '13528278', '2455091', '3107516', '62438', '13901878', '58409342', '756340', '2669165', '60756', '80081', '2470224', '3801', '5189625', '393287', '2726967', '468685', '153971', '57773', '86137', '4562022', '1493198', '25889792', '3265441', '54329', '5532160', '45072058', '1179532', '19531136', '5076976', '206835', '11488229', '2841740', '5754563', '44025521', '42522863', '6140262', '2664407', '1891079', '9651858', '5362244', '5571', '146991', '8260536', '104005', '5841963', '3882887', '924014', '424378', '127996', '5172456', '591984', '447317', '2125933', '1995633', '99383', '69852'), dtype=tf.string, default_value=-1, num_oov_buckets=0), dimension=32, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x0000028584F0D4C0>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True, use_safe_embedding_lookup=True),\n",
       " EmbeddingColumn(categorical_column=VocabularyListCategoricalColumn(key='food_name', vocabulary_list=('Kebab', 'Gyoza', 'Chicken Katsu', 'Chicken Cordon Bleu', 'Salmon Teriyaki', 'Fish and Chips', 'Fish Cake', 'Okonomiyaki', 'Coleslaw', 'Ratatouille', 'Kimchi', 'Onion Rings', 'Mashed Potato', 'Risotto', 'Pad Thai', 'Loco Moco', 'Bibimbap', 'Bubur Ayam', 'Japchae', 'Miso Soup', 'Burger Bun', 'Peanut Butter Cookies', 'Baguette', 'Takoyaki', 'Pizza Dough', 'Meringue Cookies', 'Cream Cheese', 'Bagel', 'Puff Pastry', 'Apple Strudel', 'Butter Cookies', 'Lemon Cake', 'Red Velvet', 'French Toast', 'Churros', 'Croissant', 'Cinnamon Roll', 'Chocolate Lava Cake', 'Black Forest', 'Tiramisu', 'Carrot Cake', 'Chocolate Mousse Cake', 'Cloud Bread', 'Samosa', 'Tteokbokki', 'Butterscotch Pudding', 'Thai Tea', 'Guacamole'), dtype=tf.string, default_value=-1, num_oov_buckets=0), dimension=32, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x0000028584F0D820>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True, use_safe_embedding_lookup=True),\n",
       " EmbeddingColumn(categorical_column=VocabularyListCategoricalColumn(key='food_type', vocabulary_list=('[]',), dtype=tf.string, default_value=-1, num_oov_buckets=0), dimension=8, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x0000028584F0D280>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True, use_safe_embedding_lookup=True),\n",
       " EmbeddingColumn(categorical_column=VocabularyListCategoricalColumn(key='brand_name', vocabulary_list=('0', 'Hungry Planet', 'Yoshinoya', \"Tokyo Joe's\", 'L&L Hawaiian Barbecue', \"Zippy's\", 'EastWest Cuisine', 'Hello Fresh', 'Ono Hawaiian BBQ', 'Bonchon', 'Barber Foods', 'Kroger', 'Kirkwood', 'A La Carte', 'HEB', 'Wegmans', 'Freshly', 'Ruprecht', 'Which Wich', 'Safeway Kitchens', 'Omaha Steaks', 'Dutch Farms', 'Aqua Star', \"Schwan's\", 'Uno Chicago Grill', 'Osaki', \"Raising Cane's\", 'Signature Farms', \"Famous Dave's\", \"Nando's\", 'Bob Evans', 'Mission BBQ', 'Bill Miller Bar-B-Q', \"Abner's\", \"Bandana's Bar-B-Q\", 'Hickory River', \"Applebee's\", 'Red Lobster', \"Trader Joe's\", 'Sodexo', 'Seoul', 'Jongga', 'Chongga', 'Nasoya', \"Mother in Law's\", 'Doo San Food', 'Bibibop', 'Kimchi Pride & Foods', 'Firefly Kitchens', 'Cosmos', \"TGI Friday's\", 'Fuddruckers', 'Ore-Ida', \"Clancy's\", \"Freddy's Frozen Custard\", \"Max & Erma's\", 'Hook Burger', \"Dickey's Barbecue\", \"Portillo's\", 'Dairy Queen', 'T. J. Farms', \"Carl's Jr.\", \"Frisch's Big Boy\", \"Roundy's\", 'The Varsity', 'ShopRite', 'Giant Eagle', 'Bellino', 'NutriSystem', 'Great Value', 'Passage Foods', 'Whole Foods Market', 'Sweet Earth', 'IHOP', 'Ajinomoto', 'Ottogi', 'Miko Brand', 'Marukome', 'RA Sushi', 'Hikari Miso', 'AFC', 'Fusia', 'Butternut', 'Breadway', 'Dream Dinners', \"Pamela's Products\", \"Grandma's\", '7-Eleven', 'Fat Snax', 'Jenny Craig', 'Perfect Keto', 'Artisan Fresh', 'La Bou', 'Kirkland Signature', 'Publix', 'Mimis Cafe', 'J Basket', 'Mama Cozzi', 'Pizza Buddy', 'Stop & Shop', 'Miss Meringue', 'Spaans', \"Member's Mark\", 'Butter Braid', 'Raskas', 'Lucerne', 'Wewalka', 'Deutsche Kuche', 'Au Bon Pain', 'The Royal Danish', \"Sam's Choice\", 'Mrs. Fields', 'Family Gourmet', \"hammond's\", 'Weight Watchers', 'Just Desserts', 'Cafe Valley Bakery', 'Cupcake Vineyards', 'Oreo', 'One Bar', 'Cracker Barrel Old Country Store', 'First Watch', \"Denny's\", 'Hometown Buffet', 'Jillian Michaels', 'Little Caesars', 'Baja Fresh Mexican Grill', 'Costco', 'Red Robin', 'Pillsbury', 'Tim Hortons', \"Sam's Club\", 'Corner Bakery Cafe', \"Charleston's\", \"Cheddar's\", 'La Boulange', 'Fresh & Easy', \"Baker's Treat\", 'Oats Overnight', 'Armour', \"L'oven Fresh\", 'Larabar', 'Bon Appetit', 'Souplantation', 'Sweet Tomatoes', 'Gardenia', \"Bertucci's\", 'Roma', 'Favorite Day', 'Dessert Italiano', 'Cheesecake Factory', 'Olive Garden', 'Bertolli', \"Romano's Macaroni Grill\", 'Orion', 'Sweetaly', 'Wellsley Farms', 'Balconi', \"Carino's Italian Restaurant\", 'Archer Farms', 'Taste It', 'Market Day', \"Jason's Deli\", 'Vachon', 'Outback Steakhouse', \"J. Alexander's\", 'Golden Corral', \"Schlotzsky's Deli\", \"Ne-Mo's Bakery\", 'Pita Jungle', \"Mrs. Freshley's\", 'Chunkie Dunkies', \"Gandolfo's\", 'Cafe Zupas', 'Hooters', 'Deep', \"Haldiram's\", 'Snack Pack', 'Jell-O', 'SlimGenics', 'Swiss Miss', 'Green Fields', 'Taste Nirvana', 'Del Monte', 'Yucatan', 'Cabo Fresh', 'Sabra', 'Signature Cafe', 'Taco Bueno', 'Little Salad Bar', 'Taco Cabana', \"Chevy's Fresh Mex\", 'Costa Vida', 'Ortega', \"Chili's\", 'Freebirds'), dtype=tf.string, default_value=-1, num_oov_buckets=0), dimension=16, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x0000028584F5C280>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True, use_safe_embedding_lookup=True),\n",
       " NumericColumn(key='calcium', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='calories', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='carbohydrate', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='cholesterol', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='fat', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='fiber', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='iron', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " EmbeddingColumn(categorical_column=VocabularyListCategoricalColumn(key='measurement_description', vocabulary_list=('kebab', 'serving (390g)', 'g', 'oz', 'serving', 'pancake', 'serving (240g)', 'tbsp', 'cup', 'lb', 'serving (107g)', 'small (1-3/4\" to 2-1/4\" dia, raw) yields', 'medium (2-1/4\" to 3\" dia, raw) yields', 'large (3\" to 4-1/4\" dia, raw) yields', 'long type (2-1/3\" dia, 4-3/4\" long, raw) yields', 'serving (105g)', 'serving (210g)', 'cookie', 'cubic inch', 'slice, crust not eaten', 'serving (64g)', 'mini baguette (about 9\" long)', 'baguette (about 22\" long)', 'small slice', 'medium slice', 'large slice', 'ball', 'tbsp, whipped', 'package, small (3 oz)', 'small package (3 oz)', 'tablespoon', 'tablespoon, whipped', 'serving (22g)', 'individual container', 'miniature', 'small', 'regular', 'large', 'pastry', 'patty shell', 'serving (11g)', 'piece', 'piece (approx 2\" - 2-1/2\" square)', '2-layer cake (8\" or 9\" dia, 4\" high)', '1-layer cake (8\" or 9\" dia, 2\" high)', 'bundt or tube cake', 'piece (1/12 of 2-layer, 8\" or 9\" dia)', 'piece (1/10 of 1-layer, 8\" or 9\" dia)', 'serving (109g)', 'churro', 'serving (26g)', 'frozen', 'mini croissant', 'serving (56g)', 'small croissant', 'medium croissant', 'large croissant'), dtype=tf.string, default_value=-1, num_oov_buckets=0), dimension=8, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x0000028584F5ED00>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True, use_safe_embedding_lookup=True),\n",
       " NumericColumn(key='metric_serving_amount', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " EmbeddingColumn(categorical_column=VocabularyListCategoricalColumn(key='metric_serving_unit', vocabulary_list=('g', '0', 'oz'), dtype=tf.string, default_value=-1, num_oov_buckets=0), dimension=8, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x0000028585315190>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True, use_safe_embedding_lookup=True),\n",
       " NumericColumn(key='monounsaturated_fat', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='number_of_units', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='polyunsaturated_fat', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='potassium', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='protein', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='saturated_fat', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " EmbeddingColumn(categorical_column=VocabularyListCategoricalColumn(key='serving_description', vocabulary_list=('1 kebab', '1 serving (390 g)', '100 g', '1 oz', '4 gyoza', '5 pieces', '1 serving', '1 piece', '1 chicken', '5 oz', '1 tray', '1 breast', '1 sandwich', '1 package', '1 container', '1 bowl', '1 steamed pouch', '2 servings', '5 sticks', '1 pancake', '1 serving (240 g)', '1 tbsp', '1/2 cup', '1 lb', '1 1/2 cups', '1 cup', '1 portion', '1 serving (107 g)', '2 tbsp', '8 oz', '3 rings', '4 rings', '6 rings', '1 side', '6 oz', '8-9 rings', '5 rings', '6 pieces', '4 pieces', '1 small (1-3/4\" to 2-1/4\" dia, raw) yields', '1 medium (2-1/4\" to 3\" dia, raw) yields', '1 large (3\" to 4-1/4\" dia, raw) yields', '1 long type (2-1/3\" dia, 4-3/4\" long, raw) yields', '1 serving (105 g)', '1/4 cup', '1 serving (210 g)', '1/2 bag', '1/2 container', '1 packet', '3/4 tbsp', '1 bun', '1 cookie', '2 cookies', '1 bag', '1 cubic inch', '1 slice, crust not eaten', '1 serving (64 g)', '1 mini (about 9\" long)', '1 regular (about 22\" long)', '1 small slice', '1 medium slice', '1 large slice', '1 slice', '2 oz', '1 ball', '3 pieces', '1/8 crust', '1/8 dough ball', '1/8 package', '11 cookies', '15 cookies', '1 tbsp whipped', '1 package, small (3 oz)', '1 small package (3 oz)', '1 serving (22 g)', '1 individual container', '1 miniature', '1 small', '1 regular', '1 large', '1 bagel', '1 pastry', '1 patty shell', '1 serving (11 g)', '1/8 sheet', '1/6 package', '1 piece (approx 2\" - 2-1/2\" square)', '1/3 strudel', '1 square', '1/6 strudel', '3 cookies', '6 cookies', '4 cookies', '5 cookies', '1 2-layer cake serving (8\" or 9\" dia, 4\" high)', '1 1-layer cake serving (8\" or 9\" dia, 2\" high)', '1 bundt or tube cake', '1 piece (1/12 2-layer, 8\" or 9\" dia)', '1 piece (1/10 1-layer, 8\" or 9\" dia)', '1 serving (109 g)', '1 cake', '1 mini cake', '1 bar', '3 slices', '2 slices', '2 pieces', '1 churro', '1 serving (26 g)', '1 stick', '1 frozen', '1 mini', '1 serving (56 g)', '1 medium', '1 croissant'), dtype=tf.string, default_value=-1, num_oov_buckets=0), dimension=8, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x000002858534E220>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True, use_safe_embedding_lookup=True),\n",
       " EmbeddingColumn(categorical_column=VocabularyListCategoricalColumn(key='serving_id', vocabulary_list=('2590791', '2590792', '2590793', '2590794', '48898797', '56328404', '540893', '1659243', '393671', '43834428', '31594667', '1723549', '49446206', '3357112', '1546023', '867589', '6692797', '42983759', '265992', '46122518', '1270767', '2228184', '6500664', '112379', '5253910', '47660467', '2408844', '236515', '1833645', '21380023', '21380014', '21380015', '21380016', '34095', '34096', '44091', '48738', '59077', '137595', '41187290', '1870896', '14897235', '436917', '11555463', '2998818', '404632', '8843780', '7283581', '3220710', '196085', '26245', '25438', '55388', '184095', '153533', '3208689', '12868131', '4564786', '36089568', '27598183', '25945555', '18228469', '15756470', '40060714', '45687379', '11487081', '12685450', '6040308', '109426', '592200', '5411410', '1028203', '1793435', '761994', '3946978', '13027320', '117928', '2883464', '212825', '114022', '131551', '12715589', '109243', '1652247', '1154672', '3161416', '285703', '21054', '21403', '21785', '21017', '22051', '20947', '54457', '183361', '109097', '393723', '1445343', '4698293', '5700405', '5700406', '5700407', '5700408', '53923934', '16761786', '13925161', '15398087', '56434996', '26659909', '14223738', '14223739', '14223740', '14223741', '44902424', '54307109', '46126793', '10438', '10502', '51981', '181481', '7288600', '857336', '7835943', '3857534', '5141813', '8306228', '3232049', '1998069', '39785040', '1945715', '38844', '38845', '61638', '4866669', '219940', '2263101', '332901', '16899693', '23728182', '35026912', '2220360', '319818', '319819', '319821', '319822', '319823', '319825', '319826', '319827', '319828', '319829', '1155063', '35554235', '51904665', '484031', '5627124', '5627125', '5627126', '54822927', '98447', '47640543', '23948913', '212560', '2426507', '7034036', '29154', '29155', '29156', '29157', '29158', '29159', '48611', '56428', '4032004', '112455', '1326', '1082', '1083', '1084', '1327', '1328', '1085', '49977', '12309276', '2555351', '3543759', '421771', '13079', '13341', '13496', '12770', '11896', '52220', '181674', '39110375', '54553543', '15498', '15356', '14208', '52884', '182323', '38059423', '34058222', '39263', '39264', '61790', '16779', '14313', '13765', '52862', '182302', '1144273', '1135384', '238191', '148096', '29955378', '1406001', '13152834', '108834', '6987128', '14115', '14116', '13717', '12436', '15120', '13419', '13032', '14371', '52536', '181983', '56280456', '53812424', '82852', '3046981', '18324235', '3283736', '8730458', '19398017', '2682614', '1706296', '9549834', '118058', '11751582', '405016', '861854', '1118510', '15082', '16875', '52903', '182338', '217282', '270542', '13154', '13232', '14681', '13162', '13155', '14587', '52213', '112629', '56535626', '44521664', '56209720', '4438697', '864426'), dtype=tf.string, default_value=-1, num_oov_buckets=0), dimension=32, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x000002858534E1F0>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True, use_safe_embedding_lookup=True),\n",
       " EmbeddingColumn(categorical_column=VocabularyListCategoricalColumn(key='favoriteFood', vocabulary_list=('Kebab', 'Gyoza', 'Chicken Katsu', 'Chicken Cordon Bleu', 'Salmon Teriyaki', 'Fish and Chips', 'Fish Cake', 'Okonomiyaki', 'Coleslaw', 'Ratatouille', 'Kimchi', 'Onion Rings', 'Mashed Potato', 'Risotto', 'Pad Thai', 'Loco Moco', 'Bibimbap', 'Bubur Ayam', 'Japchae', 'Miso Soup', 'Burger Bun', 'Peanut Butter Cookies', 'Baguette', 'Takoyaki', 'Pizza Dough', 'Meringue Cookies', 'Cream Cheese', 'Bagel', 'Puff Pastry', 'Apple Strudel', 'Butter Cookies', 'Lemon Cake', 'Red Velvet', 'French Toast', 'Churros', 'Croissant', 'Cinnamon Roll', 'Chocolate Lava Cake', 'Black Forest', 'Tiramisu', 'Carrot Cake', 'Chocolate Mousse Cake', 'Cloud Bread', 'Samosa', 'Tteokbokki', 'Butterscotch Pudding', 'Thai Tea', 'Guacamole'), dtype=tf.string, default_value=-1, num_oov_buckets=0), dimension=8, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x0000028585354F10>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True, use_safe_embedding_lookup=True),\n",
       " EmbeddingColumn(categorical_column=VocabularyListCategoricalColumn(key='birthdate', vocabulary_list=('09-01-2019', '26-08-1967', '20-01-1972', '20-03-1978', '21-04-2014', '12-09-2007', '12-11-1952', '04-01-1998', '03-03-1984', '14-04-1972', '07-08-1993', '04-05-2016', '07-08-1972', '02-05-2003', '27-05-1977', '05-02-2018', '23-03-1993', '05-10-2019', '10-05-1969', '26-04-1974', '02-03-2004', '09-09-1986', '19-05-2006', '13-02-1984', '07-10-1974', '24-02-1974', '26-11-1969', '16-06-1953', '25-04-1982', '09-01-1957', '10-10-1968', '02-01-1952', '24-03-2022', '14-05-2006', '18-06-2016', '13-01-2009', '21-07-2013', '21-01-1955', '23-01-1975', '07-03-1985', '11-05-1953', '24-04-1965', '23-11-1998', '15-12-1950', '13-10-2005', '04-10-1967', '03-06-1982', '02-03-2017', '14-04-2007', '15-04-2017', '17-06-2010', '02-08-1950', '13-01-1976', '17-01-2022', '26-01-2020', '15-05-1972', '15-11-2013', '13-05-1966', '23-09-1963', '28-09-1957', '23-06-2003', '02-12-1968', '19-07-1966', '17-03-1965', '01-05-2019', '22-03-1988', '17-06-1990', '13-07-1967', '23-09-1961', '10-04-1993', '27-07-1963', '20-07-1981', '13-02-1962', '18-06-2023', '19-06-1983', '18-04-1975', '28-08-2014', '08-09-1957', '26-03-1981', '22-12-1979', '21-11-1994', '17-11-1958', '04-05-1972', '05-09-2006', '10-06-2016', '14-02-2004', '12-12-1991', '25-04-1973', '15-06-1976', '07-06-2004', '13-08-2005', '15-09-2014', '20-10-1990', '15-06-2004', '03-01-1967', '04-07-1976', '16-10-2017', '18-08-1952', '24-10-1962', '15-05-2020', '11-11-2009', '22-03-2020', '16-08-1975', '07-10-1960', '16-10-1958', '05-08-1963', '09-02-1979', '19-09-2021', '05-01-2018', '14-09-1961', '15-07-1984', '13-10-2015', '24-10-1984', '11-08-1953', '27-02-2005', '24-01-1974', '26-01-1975', '08-07-1979', '13-08-1951', '09-03-2015', '10-02-2001', '06-09-2017', '22-06-1952', '25-07-1951', '26-07-1989', '07-01-1962', '01-01-1966', '22-11-2022', '07-06-2014', '20-02-1957', '01-08-1985', '23-02-2000', '27-07-1979', '07-01-1961', '01-02-2009', '06-07-1983', '03-06-2020', '12-07-1989', '06-02-1983', '10-05-1979', '05-10-2008', '18-12-1964', '25-10-1961', '23-01-1989', '16-05-1963', '09-09-1980', '06-12-2001', '11-08-1966', '24-07-1990', '15-12-2002', '06-06-2010', '25-04-2022', '23-02-1951', '20-06-2010', '25-11-2005', '24-04-1989', '18-05-2021', '06-10-1962', '10-09-1976', '02-06-1979', '01-09-1996', '20-02-2011', '21-06-2001', '08-11-1961', '15-07-1982', '20-12-1994', '19-09-2012', '18-10-1983', '10-11-2014', '22-05-1987', '16-10-1954', '27-10-1981', '28-09-1966', '22-01-1961', '08-01-1951', '01-10-2023', '24-05-1993', '20-08-1953', '04-10-1978', '02-11-1999', '26-06-1979', '06-11-2015', '04-06-2015', '01-12-2019', '26-06-1988', '09-03-1970', '16-10-2016', '02-11-1965', '16-06-2006', '02-11-1992', '05-10-2002', '25-07-2019', '16-12-2015', '26-04-1989', '08-02-2000', '03-01-2002', '12-10-1996', '11-07-1977', '10-11-1979', '27-08-1972', '18-06-1966', '08-08-1960', '12-03-2006', '22-11-1980', '03-10-1952', '25-12-1964', '03-07-1966', '06-05-1987', '08-01-2002', '12-09-1953', '21-02-1988', '26-11-1955', '16-12-1998', '24-02-1995', '21-07-2016', '08-11-2023', '21-06-1987', '25-12-1981', '26-07-1992', '12-08-1982', '17-03-1988', '03-07-1983', '09-12-2020', '06-09-1962', '01-10-2015', '21-08-2011', '04-11-1987', '15-07-1957', '11-10-1955', '15-06-1977', '24-11-1965', '14-11-2015', '19-08-1977', '26-04-1963', '11-03-2014', '03-04-1986', '25-10-1998', '22-03-1966', '20-07-2007', '12-06-1985', '20-07-1991', '20-10-2007', '25-06-1991', '18-02-2014', '05-09-1962', '22-10-1952', '18-08-2019', '28-12-2020', '26-12-1998', '14-12-2023', '17-04-2012', '14-05-1950', '13-09-2019', '05-10-2007', '24-03-2019', '08-09-2023', '24-03-2021', '05-03-1985', '05-04-1979', '21-10-1977', '25-07-1996', '16-07-1998', '19-12-1995', '02-11-1972', '06-06-2021'), dtype=tf.string, default_value=-1, num_oov_buckets=0), dimension=16, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x00000285853B53A0>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True, use_safe_embedding_lookup=True),\n",
       " EmbeddingColumn(categorical_column=VocabularyListCategoricalColumn(key='gender', vocabulary_list=('Male', 'Female'), dtype=tf.string, default_value=-1, num_oov_buckets=0), dimension=8, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x00000285853B5C10>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True, use_safe_embedding_lookup=True),\n",
       " NumericColumn(key='weight', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " EmbeddingColumn(categorical_column=VocabularyListCategoricalColumn(key='goals', vocabulary_list=('0', '500', '-500'), dtype=tf.string, default_value=-1, num_oov_buckets=0), dimension=8, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x00000285853B59D0>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True, use_safe_embedding_lookup=True),\n",
       " EmbeddingColumn(categorical_column=VocabularyListCategoricalColumn(key='disease', vocabulary_list=('o, ,,  , b, ,,  , e, ,,  , s, ,,  , i, ,,  , t, ,,  , y, ,,  , ,, ,,  ,  , ,,  , d, ,,  , i, ,,  , a, ,,  , b, ,,  , e, ,,  , t, ,,  , e, ,,  , s, ,,  , ,, ,,  ,  , ,,  , h, ,,  , e, ,,  , a, ,,  , r, ,,  , t, ,,  , ,, ,,  ,  , ,,  , h, ,,  , y, ,,  , p, ,,  , e, ,,  , r, ,,  , t, ,,  , e, ,,  , n, ,,  , s, ,,  , i, ,,  , o, ,,  , n', 'h, ,,  , e, ,,  , a, ,,  , r, ,,  , t, ,,  , ,, ,,  ,  , ,,  , d, ,,  , i, ,,  , a, ,,  , b, ,,  , e, ,,  , t, ,,  , e, ,,  , s, ,,  , ,, ,,  ,  , ,,  , o, ,,  , b, ,,  , e, ,,  , s, ,,  , i, ,,  , t, ,,  , y, ,,  , ,, ,,  ,  , ,,  , h, ,,  , y, ,,  , p, ,,  , e, ,,  , r, ,,  , t, ,,  , e, ,,  , n, ,,  , s, ,,  , i, ,,  , o, ,,  , n', 'h, ,,  , e, ,,  , a, ,,  , r, ,,  , t, ,,  , ,, ,,  ,  , ,,  , h, ,,  , y, ,,  , p, ,,  , e, ,,  , r, ,,  , t, ,,  , e, ,,  , n, ,,  , s, ,,  , i, ,,  , o, ,,  , n, ,,  , ,, ,,  ,  , ,,  , o, ,,  , b, ,,  , e, ,,  , s, ,,  , i, ,,  , t, ,,  , y, ,,  , ,, ,,  ,  , ,,  , d, ,,  , i, ,,  , a, ,,  , b, ,,  , e, ,,  , t, ,,  , e, ,,  , s', 'h, ,,  , y, ,,  , p, ,,  , e, ,,  , r, ,,  , t, ,,  , e, ,,  , n, ,,  , s, ,,  , i, ,,  , o, ,,  , n, ,,  , ,, ,,  ,  , ,,  , d, ,,  , i, ,,  , a, ,,  , b, ,,  , e, ,,  , t, ,,  , e, ,,  , s, ,,  , ,, ,,  ,  , ,,  , h, ,,  , e, ,,  , a, ,,  , r, ,,  , t, ,,  , ,, ,,  ,  , ,,  , o, ,,  , b, ,,  , e, ,,  , s, ,,  , i, ,,  , t, ,,  , y', 'd, ,,  , i, ,,  , a, ,,  , b, ,,  , e, ,,  , t, ,,  , e, ,,  , s', 'h, ,,  , y, ,,  , p, ,,  , e, ,,  , r, ,,  , t, ,,  , e, ,,  , n, ,,  , s, ,,  , i, ,,  , o, ,,  , n, ,,  , ,, ,,  ,  , ,,  , o, ,,  , b, ,,  , e, ,,  , s, ,,  , i, ,,  , t, ,,  , y, ,,  , ,, ,,  ,  , ,,  , h, ,,  , e, ,,  , a, ,,  , r, ,,  , t, ,,  , ,, ,,  ,  , ,,  , d, ,,  , i, ,,  , a, ,,  , b, ,,  , e, ,,  , t, ,,  , e, ,,  , s', 'h, ,,  , e, ,,  , a, ,,  , r, ,,  , t, ,,  , ,, ,,  ,  , ,,  , o, ,,  , b, ,,  , e, ,,  , s, ,,  , i, ,,  , t, ,,  , y', 'h, ,,  , y, ,,  , p, ,,  , e, ,,  , r, ,,  , t, ,,  , e, ,,  , n, ,,  , s, ,,  , i, ,,  , o, ,,  , n, ,,  , ,, ,,  ,  , ,,  , h, ,,  , e, ,,  , a, ,,  , r, ,,  , t, ,,  , ,, ,,  ,  , ,,  , o, ,,  , b, ,,  , e, ,,  , s, ,,  , i, ,,  , t, ,,  , y', 'h, ,,  , e, ,,  , a, ,,  , r, ,,  , t, ,,  , ,, ,,  ,  , ,,  , o, ,,  , b, ,,  , e, ,,  , s, ,,  , i, ,,  , t, ,,  , y, ,,  , ,, ,,  ,  , ,,  , d, ,,  , i, ,,  , a, ,,  , b, ,,  , e, ,,  , t, ,,  , e, ,,  , s, ,,  , ,, ,,  ,  , ,,  , h, ,,  , y, ,,  , p, ,,  , e, ,,  , r, ,,  , t, ,,  , e, ,,  , n, ,,  , s, ,,  , i, ,,  , o, ,,  , n', 'o, ,,  , b, ,,  , e, ,,  , s, ,,  , i, ,,  , t, ,,  , y, ,,  , ,, ,,  ,  , ,,  , h, ,,  , e, ,,  , a, ,,  , r, ,,  , t', 'h, ,,  , e, ,,  , a, ,,  , r, ,,  , t, ,,  , ,, ,,  ,  , ,,  , o, ,,  , b, ,,  , e, ,,  , s, ,,  , i, ,,  , t, ,,  , y, ,,  , ,, ,,  ,  , ,,  , d, ,,  , i, ,,  , a, ,,  , b, ,,  , e, ,,  , t, ,,  , e, ,,  , s', 'h, ,,  , y, ,,  , p, ,,  , e, ,,  , r, ,,  , t, ,,  , e, ,,  , n, ,,  , s, ,,  , i, ,,  , o, ,,  , n', '', 'd, ,,  , i, ,,  , a, ,,  , b, ,,  , e, ,,  , t, ,,  , e, ,,  , s, ,,  , ,, ,,  ,  , ,,  , o, ,,  , b, ,,  , e, ,,  , s, ,,  , i, ,,  , t, ,,  , y, ,,  , ,, ,,  ,  , ,,  , h, ,,  , e, ,,  , a, ,,  , r, ,,  , t', 'd, ,,  , i, ,,  , a, ,,  , b, ,,  , e, ,,  , t, ,,  , e, ,,  , s, ,,  , ,, ,,  ,  , ,,  , h, ,,  , y, ,,  , p, ,,  , e, ,,  , r, ,,  , t, ,,  , e, ,,  , n, ,,  , s, ,,  , i, ,,  , o, ,,  , n', 'o, ,,  , b, ,,  , e, ,,  , s, ,,  , i, ,,  , t, ,,  , y, ,,  , ,, ,,  ,  , ,,  , d, ,,  , i, ,,  , a, ,,  , b, ,,  , e, ,,  , t, ,,  , e, ,,  , s, ,,  , ,, ,,  ,  , ,,  , h, ,,  , y, ,,  , p, ,,  , e, ,,  , r, ,,  , t, ,,  , e, ,,  , n, ,,  , s, ,,  , i, ,,  , o, ,,  , n', 'o, ,,  , b, ,,  , e, ,,  , s, ,,  , i, ,,  , t, ,,  , y, ,,  , ,, ,,  ,  , ,,  , d, ,,  , i, ,,  , a, ,,  , b, ,,  , e, ,,  , t, ,,  , e, ,,  , s, ,,  , ,, ,,  ,  , ,,  , h, ,,  , e, ,,  , a, ,,  , r, ,,  , t', 'o, ,,  , b, ,,  , e, ,,  , s, ,,  , i, ,,  , t, ,,  , y, ,,  , ,, ,,  ,  , ,,  , h, ,,  , y, ,,  , p, ,,  , e, ,,  , r, ,,  , t, ,,  , e, ,,  , n, ,,  , s, ,,  , i, ,,  , o, ,,  , n, ,,  , ,, ,,  ,  , ,,  , d, ,,  , i, ,,  , a, ,,  , b, ,,  , e, ,,  , t, ,,  , e, ,,  , s', 'h, ,,  , e, ,,  , a, ,,  , r, ,,  , t, ,,  , ,, ,,  ,  , ,,  , h, ,,  , y, ,,  , p, ,,  , e, ,,  , r, ,,  , t, ,,  , e, ,,  , n, ,,  , s, ,,  , i, ,,  , o, ,,  , n', 'h, ,,  , e, ,,  , a, ,,  , r, ,,  , t', 'o, ,,  , b, ,,  , e, ,,  , s, ,,  , i, ,,  , t, ,,  , y', 'h, ,,  , y, ,,  , p, ,,  , e, ,,  , r, ,,  , t, ,,  , e, ,,  , n, ,,  , s, ,,  , i, ,,  , o, ,,  , n, ,,  , ,, ,,  ,  , ,,  , o, ,,  , b, ,,  , e, ,,  , s, ,,  , i, ,,  , t, ,,  , y, ,,  , ,, ,,  ,  , ,,  , d, ,,  , i, ,,  , a, ,,  , b, ,,  , e, ,,  , t, ,,  , e, ,,  , s, ,,  , ,, ,,  ,  , ,,  , h, ,,  , e, ,,  , a, ,,  , r, ,,  , t', 'd, ,,  , i, ,,  , a, ,,  , b, ,,  , e, ,,  , t, ,,  , e, ,,  , s, ,,  , ,, ,,  ,  , ,,  , h, ,,  , e, ,,  , a, ,,  , r, ,,  , t', 'h, ,,  , y, ,,  , p, ,,  , e, ,,  , r, ,,  , t, ,,  , e, ,,  , n, ,,  , s, ,,  , i, ,,  , o, ,,  , n, ,,  , ,, ,,  ,  , ,,  , d, ,,  , i, ,,  , a, ,,  , b, ,,  , e, ,,  , t, ,,  , e, ,,  , s', 'o, ,,  , b, ,,  , e, ,,  , s, ,,  , i, ,,  , t, ,,  , y, ,,  , ,, ,,  ,  , ,,  , h, ,,  , e, ,,  , a, ,,  , r, ,,  , t, ,,  , ,, ,,  ,  , ,,  , d, ,,  , i, ,,  , a, ,,  , b, ,,  , e, ,,  , t, ,,  , e, ,,  , s, ,,  , ,, ,,  ,  , ,,  , h, ,,  , y, ,,  , p, ,,  , e, ,,  , r, ,,  , t, ,,  , e, ,,  , n, ,,  , s, ,,  , i, ,,  , o, ,,  , n', 'd, ,,  , i, ,,  , a, ,,  , b, ,,  , e, ,,  , t, ,,  , e, ,,  , s, ,,  , ,, ,,  ,  , ,,  , h, ,,  , y, ,,  , p, ,,  , e, ,,  , r, ,,  , t, ,,  , e, ,,  , n, ,,  , s, ,,  , i, ,,  , o, ,,  , n, ,,  , ,, ,,  ,  , ,,  , o, ,,  , b, ,,  , e, ,,  , s, ,,  , i, ,,  , t, ,,  , y', 'h, ,,  , e, ,,  , a, ,,  , r, ,,  , t, ,,  , ,, ,,  ,  , ,,  , h, ,,  , y, ,,  , p, ,,  , e, ,,  , r, ,,  , t, ,,  , e, ,,  , n, ,,  , s, ,,  , i, ,,  , o, ,,  , n, ,,  , ,, ,,  ,  , ,,  , d, ,,  , i, ,,  , a, ,,  , b, ,,  , e, ,,  , t, ,,  , e, ,,  , s, ,,  , ,, ,,  ,  , ,,  , o, ,,  , b, ,,  , e, ,,  , s, ,,  , i, ,,  , t, ,,  , y', 'd, ,,  , i, ,,  , a, ,,  , b, ,,  , e, ,,  , t, ,,  , e, ,,  , s, ,,  , ,, ,,  ,  , ,,  , o, ,,  , b, ,,  , e, ,,  , s, ,,  , i, ,,  , t, ,,  , y, ,,  , ,, ,,  ,  , ,,  , h, ,,  , y, ,,  , p, ,,  , e, ,,  , r, ,,  , t, ,,  , e, ,,  , n, ,,  , s, ,,  , i, ,,  , o, ,,  , n', 'h, ,,  , y, ,,  , p, ,,  , e, ,,  , r, ,,  , t, ,,  , e, ,,  , n, ,,  , s, ,,  , i, ,,  , o, ,,  , n, ,,  , ,, ,,  ,  , ,,  , d, ,,  , i, ,,  , a, ,,  , b, ,,  , e, ,,  , t, ,,  , e, ,,  , s, ,,  , ,, ,,  ,  , ,,  , o, ,,  , b, ,,  , e, ,,  , s, ,,  , i, ,,  , t, ,,  , y', 'o, ,,  , b, ,,  , e, ,,  , s, ,,  , i, ,,  , t, ,,  , y, ,,  , ,, ,,  ,  , ,,  , d, ,,  , i, ,,  , a, ,,  , b, ,,  , e, ,,  , t, ,,  , e, ,,  , s', 'd, ,,  , i, ,,  , a, ,,  , b, ,,  , e, ,,  , t, ,,  , e, ,,  , s, ,,  , ,, ,,  ,  , ,,  , h, ,,  , y, ,,  , p, ,,  , e, ,,  , r, ,,  , t, ,,  , e, ,,  , n, ,,  , s, ,,  , i, ,,  , o, ,,  , n, ,,  , ,, ,,  ,  , ,,  , h, ,,  , e, ,,  , a, ,,  , r, ,,  , t', 'd, ,,  , i, ,,  , a, ,,  , b, ,,  , e, ,,  , t, ,,  , e, ,,  , s, ,,  , ,, ,,  ,  , ,,  , h, ,,  , y, ,,  , p, ,,  , e, ,,  , r, ,,  , t, ,,  , e, ,,  , n, ,,  , s, ,,  , i, ,,  , o, ,,  , n, ,,  , ,, ,,  ,  , ,,  , o, ,,  , b, ,,  , e, ,,  , s, ,,  , i, ,,  , t, ,,  , y, ,,  , ,, ,,  ,  , ,,  , h, ,,  , e, ,,  , a, ,,  , r, ,,  , t', 'h, ,,  , y, ,,  , p, ,,  , e, ,,  , r, ,,  , t, ,,  , e, ,,  , n, ,,  , s, ,,  , i, ,,  , o, ,,  , n, ,,  , ,, ,,  ,  , ,,  , h, ,,  , e, ,,  , a, ,,  , r, ,,  , t, ,,  , ,, ,,  ,  , ,,  , d, ,,  , i, ,,  , a, ,,  , b, ,,  , e, ,,  , t, ,,  , e, ,,  , s', 'd, ,,  , i, ,,  , a, ,,  , b, ,,  , e, ,,  , t, ,,  , e, ,,  , s, ,,  , ,, ,,  ,  , ,,  , h, ,,  , e, ,,  , a, ,,  , r, ,,  , t, ,,  , ,, ,,  ,  , ,,  , o, ,,  , b, ,,  , e, ,,  , s, ,,  , i, ,,  , t, ,,  , y', 'h, ,,  , e, ,,  , a, ,,  , r, ,,  , t, ,,  , ,, ,,  ,  , ,,  , h, ,,  , y, ,,  , p, ,,  , e, ,,  , r, ,,  , t, ,,  , e, ,,  , n, ,,  , s, ,,  , i, ,,  , o, ,,  , n, ,,  , ,, ,,  ,  , ,,  , d, ,,  , i, ,,  , a, ,,  , b, ,,  , e, ,,  , t, ,,  , e, ,,  , s', 'o, ,,  , b, ,,  , e, ,,  , s, ,,  , i, ,,  , t, ,,  , y, ,,  , ,, ,,  ,  , ,,  , h, ,,  , y, ,,  , p, ,,  , e, ,,  , r, ,,  , t, ,,  , e, ,,  , n, ,,  , s, ,,  , i, ,,  , o, ,,  , n, ,,  , ,, ,,  ,  , ,,  , d, ,,  , i, ,,  , a, ,,  , b, ,,  , e, ,,  , t, ,,  , e, ,,  , s, ,,  , ,, ,,  ,  , ,,  , h, ,,  , e, ,,  , a, ,,  , r, ,,  , t', 'h, ,,  , e, ,,  , a, ,,  , r, ,,  , t, ,,  , ,, ,,  ,  , ,,  , d, ,,  , i, ,,  , a, ,,  , b, ,,  , e, ,,  , t, ,,  , e, ,,  , s, ,,  , ,, ,,  ,  , ,,  , o, ,,  , b, ,,  , e, ,,  , s, ,,  , i, ,,  , t, ,,  , y', 'd, ,,  , i, ,,  , a, ,,  , b, ,,  , e, ,,  , t, ,,  , e, ,,  , s, ,,  , ,, ,,  ,  , ,,  , h, ,,  , e, ,,  , a, ,,  , r, ,,  , t, ,,  , ,, ,,  ,  , ,,  , h, ,,  , y, ,,  , p, ,,  , e, ,,  , r, ,,  , t, ,,  , e, ,,  , n, ,,  , s, ,,  , i, ,,  , o, ,,  , n', 'h, ,,  , y, ,,  , p, ,,  , e, ,,  , r, ,,  , t, ,,  , e, ,,  , n, ,,  , s, ,,  , i, ,,  , o, ,,  , n, ,,  , ,, ,,  ,  , ,,  , d, ,,  , i, ,,  , a, ,,  , b, ,,  , e, ,,  , t, ,,  , e, ,,  , s, ,,  , ,, ,,  ,  , ,,  , h, ,,  , e, ,,  , a, ,,  , r, ,,  , t', 'd, ,,  , i, ,,  , a, ,,  , b, ,,  , e, ,,  , t, ,,  , e, ,,  , s, ,,  , ,, ,,  ,  , ,,  , o, ,,  , b, ,,  , e, ,,  , s, ,,  , i, ,,  , t, ,,  , y, ,,  , ,, ,,  ,  , ,,  , h, ,,  , y, ,,  , p, ,,  , e, ,,  , r, ,,  , t, ,,  , e, ,,  , n, ,,  , s, ,,  , i, ,,  , o, ,,  , n, ,,  , ,, ,,  ,  , ,,  , h, ,,  , e, ,,  , a, ,,  , r, ,,  , t', 'd, ,,  , i, ,,  , a, ,,  , b, ,,  , e, ,,  , t, ,,  , e, ,,  , s, ,,  , ,, ,,  ,  , ,,  , o, ,,  , b, ,,  , e, ,,  , s, ,,  , i, ,,  , t, ,,  , y', 'o, ,,  , b, ,,  , e, ,,  , s, ,,  , i, ,,  , t, ,,  , y, ,,  , ,, ,,  ,  , ,,  , d, ,,  , i, ,,  , a, ,,  , b, ,,  , e, ,,  , t, ,,  , e, ,,  , s, ,,  , ,, ,,  ,  , ,,  , h, ,,  , y, ,,  , p, ,,  , e, ,,  , r, ,,  , t, ,,  , e, ,,  , n, ,,  , s, ,,  , i, ,,  , o, ,,  , n, ,,  , ,, ,,  ,  , ,,  , h, ,,  , e, ,,  , a, ,,  , r, ,,  , t', 'h, ,,  , y, ,,  , p, ,,  , e, ,,  , r, ,,  , t, ,,  , e, ,,  , n, ,,  , s, ,,  , i, ,,  , o, ,,  , n, ,,  , ,, ,,  ,  , ,,  , o, ,,  , b, ,,  , e, ,,  , s, ,,  , i, ,,  , t, ,,  , y', 'o, ,,  , b, ,,  , e, ,,  , s, ,,  , i, ,,  , t, ,,  , y, ,,  , ,, ,,  ,  , ,,  , h, ,,  , e, ,,  , a, ,,  , r, ,,  , t, ,,  , ,, ,,  ,  , ,,  , h, ,,  , y, ,,  , p, ,,  , e, ,,  , r, ,,  , t, ,,  , e, ,,  , n, ,,  , s, ,,  , i, ,,  , o, ,,  , n, ,,  , ,, ,,  ,  , ,,  , d, ,,  , i, ,,  , a, ,,  , b, ,,  , e, ,,  , t, ,,  , e, ,,  , s', 'd, ,,  , i, ,,  , a, ,,  , b, ,,  , e, ,,  , t, ,,  , e, ,,  , s, ,,  , ,, ,,  ,  , ,,  , o, ,,  , b, ,,  , e, ,,  , s, ,,  , i, ,,  , t, ,,  , y, ,,  , ,, ,,  ,  , ,,  , h, ,,  , e, ,,  , a, ,,  , r, ,,  , t, ,,  , ,, ,,  ,  , ,,  , h, ,,  , y, ,,  , p, ,,  , e, ,,  , r, ,,  , t, ,,  , e, ,,  , n, ,,  , s, ,,  , i, ,,  , o, ,,  , n', 'd, ,,  , i, ,,  , a, ,,  , b, ,,  , e, ,,  , t, ,,  , e, ,,  , s, ,,  , ,, ,,  ,  , ,,  , h, ,,  , e, ,,  , a, ,,  , r, ,,  , t, ,,  , ,, ,,  ,  , ,,  , o, ,,  , b, ,,  , e, ,,  , s, ,,  , i, ,,  , t, ,,  , y, ,,  , ,, ,,  ,  , ,,  , h, ,,  , y, ,,  , p, ,,  , e, ,,  , r, ,,  , t, ,,  , e, ,,  , n, ,,  , s, ,,  , i, ,,  , o, ,,  , n', 'h, ,,  , y, ,,  , p, ,,  , e, ,,  , r, ,,  , t, ,,  , e, ,,  , n, ,,  , s, ,,  , i, ,,  , o, ,,  , n, ,,  , ,, ,,  ,  , ,,  , h, ,,  , e, ,,  , a, ,,  , r, ,,  , t', 'h, ,,  , e, ,,  , a, ,,  , r, ,,  , t, ,,  , ,, ,,  ,  , ,,  , d, ,,  , i, ,,  , a, ,,  , b, ,,  , e, ,,  , t, ,,  , e, ,,  , s, ,,  , ,, ,,  ,  , ,,  , h, ,,  , y, ,,  , p, ,,  , e, ,,  , r, ,,  , t, ,,  , e, ,,  , n, ,,  , s, ,,  , i, ,,  , o, ,,  , n, ,,  , ,, ,,  ,  , ,,  , o, ,,  , b, ,,  , e, ,,  , s, ,,  , i, ,,  , t, ,,  , y', 'o, ,,  , b, ,,  , e, ,,  , s, ,,  , i, ,,  , t, ,,  , y, ,,  , ,, ,,  ,  , ,,  , h, ,,  , y, ,,  , p, ,,  , e, ,,  , r, ,,  , t, ,,  , e, ,,  , n, ,,  , s, ,,  , i, ,,  , o, ,,  , n, ,,  , ,, ,,  ,  , ,,  , h, ,,  , e, ,,  , a, ,,  , r, ,,  , t', 'h, ,,  , y, ,,  , p, ,,  , e, ,,  , r, ,,  , t, ,,  , e, ,,  , n, ,,  , s, ,,  , i, ,,  , o, ,,  , n, ,,  , ,, ,,  ,  , ,,  , o, ,,  , b, ,,  , e, ,,  , s, ,,  , i, ,,  , t, ,,  , y, ,,  , ,, ,,  ,  , ,,  , d, ,,  , i, ,,  , a, ,,  , b, ,,  , e, ,,  , t, ,,  , e, ,,  , s', 'h, ,,  , e, ,,  , a, ,,  , r, ,,  , t, ,,  , ,, ,,  ,  , ,,  , h, ,,  , y, ,,  , p, ,,  , e, ,,  , r, ,,  , t, ,,  , e, ,,  , n, ,,  , s, ,,  , i, ,,  , o, ,,  , n, ,,  , ,, ,,  ,  , ,,  , o, ,,  , b, ,,  , e, ,,  , s, ,,  , i, ,,  , t, ,,  , y', 'd, ,,  , i, ,,  , a, ,,  , b, ,,  , e, ,,  , t, ,,  , e, ,,  , s, ,,  , ,, ,,  ,  , ,,  , h, ,,  , y, ,,  , p, ,,  , e, ,,  , r, ,,  , t, ,,  , e, ,,  , n, ,,  , s, ,,  , i, ,,  , o, ,,  , n, ,,  , ,, ,,  ,  , ,,  , h, ,,  , e, ,,  , a, ,,  , r, ,,  , t, ,,  , ,, ,,  ,  , ,,  , o, ,,  , b, ,,  , e, ,,  , s, ,,  , i, ,,  , t, ,,  , y', 'o, ,,  , b, ,,  , e, ,,  , s, ,,  , i, ,,  , t, ,,  , y, ,,  , ,, ,,  ,  , ,,  , h, ,,  , y, ,,  , p, ,,  , e, ,,  , r, ,,  , t, ,,  , e, ,,  , n, ,,  , s, ,,  , i, ,,  , o, ,,  , n, ,,  , ,, ,,  ,  , ,,  , h, ,,  , e, ,,  , a, ,,  , r, ,,  , t, ,,  , ,, ,,  ,  , ,,  , d, ,,  , i, ,,  , a, ,,  , b, ,,  , e, ,,  , t, ,,  , e, ,,  , s', 'h, ,,  , y, ,,  , p, ,,  , e, ,,  , r, ,,  , t, ,,  , e, ,,  , n, ,,  , s, ,,  , i, ,,  , o, ,,  , n, ,,  , ,, ,,  ,  , ,,  , d, ,,  , i, ,,  , a, ,,  , b, ,,  , e, ,,  , t, ,,  , e, ,,  , s, ,,  , ,, ,,  ,  , ,,  , o, ,,  , b, ,,  , e, ,,  , s, ,,  , i, ,,  , t, ,,  , y, ,,  , ,, ,,  ,  , ,,  , h, ,,  , e, ,,  , a, ,,  , r, ,,  , t', 'h, ,,  , y, ,,  , p, ,,  , e, ,,  , r, ,,  , t, ,,  , e, ,,  , n, ,,  , s, ,,  , i, ,,  , o, ,,  , n, ,,  , ,, ,,  ,  , ,,  , o, ,,  , b, ,,  , e, ,,  , s, ,,  , i, ,,  , t, ,,  , y, ,,  , ,, ,,  ,  , ,,  , h, ,,  , e, ,,  , a, ,,  , r, ,,  , t', 'd, ,,  , i, ,,  , a, ,,  , b, ,,  , e, ,,  , t, ,,  , e, ,,  , s, ,,  , ,, ,,  ,  , ,,  , h, ,,  , e, ,,  , a, ,,  , r, ,,  , t, ,,  , ,, ,,  ,  , ,,  , h, ,,  , y, ,,  , p, ,,  , e, ,,  , r, ,,  , t, ,,  , e, ,,  , n, ,,  , s, ,,  , i, ,,  , o, ,,  , n, ,,  , ,, ,,  ,  , ,,  , o, ,,  , b, ,,  , e, ,,  , s, ,,  , i, ,,  , t, ,,  , y', 'o, ,,  , b, ,,  , e, ,,  , s, ,,  , i, ,,  , t, ,,  , y, ,,  , ,, ,,  ,  , ,,  , h, ,,  , y, ,,  , p, ,,  , e, ,,  , r, ,,  , t, ,,  , e, ,,  , n, ,,  , s, ,,  , i, ,,  , o, ,,  , n', 'h, ,,  , e, ,,  , a, ,,  , r, ,,  , t, ,,  , ,, ,,  ,  , ,,  , o, ,,  , b, ,,  , e, ,,  , s, ,,  , i, ,,  , t, ,,  , y, ,,  , ,, ,,  ,  , ,,  , h, ,,  , y, ,,  , p, ,,  , e, ,,  , r, ,,  , t, ,,  , e, ,,  , n, ,,  , s, ,,  , i, ,,  , o, ,,  , n', 'o, ,,  , b, ,,  , e, ,,  , s, ,,  , i, ,,  , t, ,,  , y, ,,  , ,, ,,  ,  , ,,  , h, ,,  , e, ,,  , a, ,,  , r, ,,  , t, ,,  , ,, ,,  ,  , ,,  , d, ,,  , i, ,,  , a, ,,  , b, ,,  , e, ,,  , t, ,,  , e, ,,  , s', 'h, ,,  , e, ,,  , a, ,,  , r, ,,  , t, ,,  , ,, ,,  ,  , ,,  , o, ,,  , b, ,,  , e, ,,  , s, ,,  , i, ,,  , t, ,,  , y, ,,  , ,, ,,  ,  , ,,  , h, ,,  , y, ,,  , p, ,,  , e, ,,  , r, ,,  , t, ,,  , e, ,,  , n, ,,  , s, ,,  , i, ,,  , o, ,,  , n, ,,  , ,, ,,  ,  , ,,  , d, ,,  , i, ,,  , a, ,,  , b, ,,  , e, ,,  , t, ,,  , e, ,,  , s'), dtype=tf.string, default_value=-1, num_oov_buckets=0), dimension=8, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x00000285853B5880>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True, use_safe_embedding_lookup=True)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the TFRS model and compile it\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.DenseFeatures(feature_columns),\n",
    "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))\n",
    "\n",
    "# Train the model with the feature columns\n",
    "model.fit(merged_df, epochs=10, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
